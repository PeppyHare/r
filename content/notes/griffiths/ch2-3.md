---
title: Electric Potential
weight: 230
---

# 2.3: Electric Potential

## 2.3.1: Introduction to Potential

The electric field __E__ is not just _any_ old vector function. It is a very special _kind_ of vector function: one whose curl id zero. \\( \vec{E} = y \vu{x} \\) , for example, could not possibly be an electrostatic field; _no_ set of charges, regardless of their sizes and positions, could ever produce such a field. We're going to exploit this special property of electric fields to reduce a _vector_ problem (finding __E__) to a much simpler _scalar_ problem. The first theorem in Sect 1.6.2 asserts that any vector whose curl is zero is equal to the gradient of some scalar. What I'm going to do now amounts to a proof of that claim, in the context of electrostatics.

<p align="center"> <img alt="Figure 2.30" src="/r/img/griffiths/2.30.png" /> </p>

Because \\( \nabla \cross \vec{E} = 0\\) , the line integral of __E__ around any closed loop is zero (that follows from Stokes' theorem). Because \\( \oint \vec{E} \cdot \dd{\vec{l}} = 0 \\), the line integral of __E__ from point __a__ to point __b__ is the same for all paths (otherwise you could go _out_ along path (i) and return along path (ii) - Fig 2.30 - and obtain \\( \oint \vec{E} \cdot \dd{\vec{l}} \neq 0 \\) ). Because the line integral is independent of path, we can define a function

{{< katex display >}}
V(\vec{r}) \equiv - \int _{O} ^{\vec{r}} \vec{E} \cdot \dd{\vec{l}} \label{2.21} \tag{2.21}
{{< /katex >}}


Here \\( O \\) is some standard reference point on which we have agreed beforehand; V then depends only on the point \\( \vec{r} \\). It is called the __electric potential__.

The potential _difference_ between two points __a__ and __b__ is

{{< katex display >}}
\begin{aligned}
V(\vec{b}) - V(\vec{a}) & = & -\int_{O}^{\vec{b}} \vec{E}\cdot \dd{\vec{l}} + \int_{O}^{\vec{a}} \vec{E} \cdot \dd{\vec{l}} \\
& = & -\int_{O}^{\vec{b}} \vec{E}\cdot \dd{\vec{l}} - \int_{\vec{a}}^{O} \vec{E}\cdot \dd{\vec{l}} \\
& = & - \int_{\vec{a}} ^{\vec{b}} \vec{E}\cdot \dd{\vec{l}}
\end{aligned}
\tagl{2.22}
{{< /katex >}}


Now, the fundamental theorem for gradients states that

{{< katex display >}}
V(\vec{b}) - V(\vec{a}) = \int_{\vec{a}} ^{\vec{b}} (\grad{V}) \cdot \dd{\vec{l}}
{{< /katex >}}

so

{{< katex display >}}
\int_{\vec{a}}^{\vec{b}} (\grad{V})\cdot \dd{\vec{l}} = - \int_{\vec{a}}^{\vec{b}} \vec{E}\cdot \dd{\vec{l}}
{{< /katex >}}

Since, finally, this is true for _any_ points __a__ and __b__, the integrands must be equal:

{{< katex display >}}
\vec{E} = - \grad{V} \label{2.23} \tag{2.23}
{{< /katex >}}


Equation \\( \eqref{2.23} \\) is the differential version of \\( \eqref{2.21} \\); it says that the electric field is the gradient of a scalar potential, which is what we set out to prove.

Notice the subtle but crucial role played by path independence (or, equivalently, the fact that \\( \nabla \times \vec{E} = 0 \\) ) in this argument. If the line integral of __E__ depended on the path taken, then the "definition" of V \\( \eqref{2.21} \\) would be nonsense. It simply would not define a function, since changing the path would alter the value of \\( V(\vec{r}) \\). By the way, don't let the minus sign in \\( \eqref{2.23} \\) distract you; it carries over from \\( \eqref{2.21} \\) and is largely a matter of convention.

## 2.3.2: Comments on Potential

__The name__. The word "potential" is a hideous misnomer because it inevitably reminds you of potential _energy_. This is particularly insidious, because there _is_ a connection between "potential" and "potential energy," as you will see in Sect 2.4. I'm sorry that it is impossible to escape this word. The best I can do is to insist once and for all that "potential" and "potential energy" are completely different terms and should, by all rights, have different names. Incidentially, a surface over which the potential is constant is called an __equipotential__.

__Advantage of the potential formulation__. If you know V, you can easily get __E__ - just take the gradient: \\( \vec{E} =- \grad{V} \\). This is quite extraordinary when you stop to think about it, for __E__ is a _vector_ quantity (three components), but V is a __scalar__ (one component). How can one function possibly contain all the information that three independent functions carry? The answer is that the three components of __E__ are not really as independent as they look; in fact, they are explicitly interrelated by the very condition we started with,\\( \nabla \times \vec{E} = 0 \\). In terms of components,

{{< katex display >}}
\pdv{E_x}{y} = \pdv{E_y}{x}, \qquad \pdv{E_z}{y} = \pdv{E_y}{z}, \qquad \pdv{E_x}{z} = \pdv{E_z}{x}
{{< /katex >}}


This brings us back to my observation at the beginning of Sect 2.3.1: __E__ is a very special kind of vector.What the potential formulation does is to exploit this feature to maximum advantage, reducing a vector problem to a scalar one, in which there is no need to fuss with components.

__The reference point \\( \mathscr{O} \\)__. There is an essential ambiguity in the definition of potential, since the choice of reference point \\( \mathscr{O} \\) was arbitrary. Changing reference points amounts to adding a constant K to the potential:

{{< katex display >}}
V'(r) =  -\int_{\mathscr{O}'}^{\vec{r}} \vec{E} \cdot \dd{\vec{l}} \\ 
= - \int_{\mathscr{O}'} ^{\mathscr{O}} \vec{E} \cdot \dd{\vec{l}} - \int_{\mathscr{O}}^{\vec{r}} \vec{E} \cdot \dd{\vec{l}} \\
=  K + V(\vec{r})
{{< /katex >}}


where K is the line integral of __E__ from the old reference point \\( \mathscr{O} \\) to the new one \\( \mathscr{O}' \\). Of course, adding a constant to V will not affect the potential _difference_ between two points, since the K's cancel out. Nor does the ambiguity affect the gradient of V:

{{< katex display >}}
\grad{V'} = \grad{V} 
{{< /katex >}}

since the derivative of a constant is zero. That's why all such V's, differing only in their choice of reference point, correspond to the same field __E__

Potential as such carries no real physical significance, for at any given point we can adjust its value at will by suitable relocation of \\( \mathscr{O} \\). In this sense, it is rather like altitude: if I ask you how high Denver is, you will probably tell me its height above sea level, because that is a convenient and traditional reference point. But we could as well agree to measure altitude above Washington, DC, or Greenwich, or wherever. That would add (or rather, subtract) a fixed amount from all our sea-level readings, but it wouldn't change anything about the real world. The only quantity of interest is the _difference_ in altitude between two points, and that is the same whatever your reference level.

Having said this, however, there is a "natural" spot to use for \\( \mathscr{O} \\) in electrostatics - analogous to sea level for altitude - and that is a point infinitely far from the charge. Ordinarily, then, we s"set the zero of potential at infinity." (Since \\( V(\mathscr{O}) = 0 \\), choosing a reference point is equivalent to selecting a place where \\( V \\) is to be zero.) But I must warn you that there is one special circumstance in which this convention fails: when the charge distribution itself extends to infinity. The symptom of trouble, in such cases, is that the potential blows up. For instance, the field of a uniformly charged plane is \\( (\sigma / 2 \epsilon_0) \vu{n} \\), as we found in Ex 2.5; if we naively put \\( \mathscr{O} = \infty \\), then the potential at height _z_ above the plane becomes

{{< katex display >}}
V(z) = - \int_{\infty}^{z}\frac{1}{2\epsilon_0} \sigma \dd{z} = - \frac{1}{2\epsilon_0} \sigma(z - \infty)
{{< /katex >}}
 
The remedy is simply to choose some other reference point (in this example you might use a point on the plane). Notice that the difficulty occurs only in textbook problems; in "real life" there is no such thing as a charge distribution that goes on forever, and we can _always_ use infinity as our reference point.

__Potential obeys the superposition principle__. The original superposition principle pertains to the force on a test charge Q. It says that the total force on _Q_ is the vector sum of the forces attributable to the source charges individually:

{{< katex display >}}
\vec{F} = \vec{F_1} + \vec{F_2} + \ldots
{{< /katex >}}

Dividing through by Q, we see that the electric field, too, obeys the superposition principle:

{{< katex display >}}
\vec{E} = \vec{E_1} + \vec{E_2} + \ldots \label{2.38}
{{< /katex >}}

Integrating from the common reference point to \\( \vec{r} \\), it follows that the potential also satisfies such a principle:

{{< katex display >}}
V = V_1 + V_2 + \ldots
{{< /katex >}}

That is, the potential at any given point is the sum of the potentials due to all the source charges separately. Only this time it is an _ordinary_ sum, not a vector sum, which makes it a lot easier to work with.

__Units of Potential__. In our units, force is measured in newtons and charge in coulombs, so electric fields are in newtons per coulomb. Accordingly, potential is newton-meters per coulomb, or joules per coulomb. A joule per coulomb is a __volt__.

## 2.3.3: Poisson's Equation and Laplace's Equation

We found in Sect 2.3.1 that the electric field can be written as the gradient of a scalar potential

{{< katex display >}}
\vec{E} = - \grad{V}
{{< /katex >}}

The question arises, what do the divergence and curl of __E__,

{{< katex display >}}
\div{\vec{E}} = \frac{\rho}{\epsilon_0} \qquad \text{ and } \qquad \curl{\vec{E}} = 0
{{< /katex >}}

look like, in terms of V? Well, \\( \div{\vec{E}} = \div(-\grad{V}) = -\laplacian{V} \\), so, apart from that persistent minus sign, the divergence of __E__ is the Laplacian of V. Gauss's law, then, says

{{< katex display >}}
\laplacian{V} = -\frac{\rho}{\epsilon_0} \label{2.24}
{{< /katex >}}


This is known as __Poisson's equation__. In regions where there is no charge, so \\( \rho = 0 \\), Poisson's equation reduces to Laplace's equation,

{{< katex display >}}
\laplacian{V} = 0 \label{2.25}
{{< /katex >}}


We'll explore this equation more fully in Chapter 3.

So much for Gauss's law. What about the curl law? This says that

{{< katex display >}}
\curl{\vec{E}} = \curl(-\grad{V}) = 0
{{< /katex >}}


But that's no condition on V - curl of gradient is _always_ zero. Of course, we used the curl law to show that __E__ could be expressed as the gradient of a scalar, so it's not really surprising that this works out: \\( \curl{\vec{E}} = 0 \\) permits our definition of V; in return, \\( \vec{E} = - \grad{V} \\) guarantees \\( \curl{\vec{E}} = 0 \\). It only takes one differential equation (Poisson's) to determine V, because V is a scalar. For \\( \vec{E} \\) we needed two, the divergence and the curl.

## 2.3.4: The potential of a Localized Charge Distribution

I defined V in terms of \\( \vec{E} \eqref{2.21} \\). Ordinarily, though, it's __E__ that we're looking for (if we already knew __E__, there wouldn't be much point in calculating V). The idea is that it might be easier to get V first, and then calculate __E__ by taking the gradient. Typically, then, we know where the charge is (that is, we know \\( \rho \\)), and we want to find V. Now, Poisson's equation relates V and \\( \rho \\), but unfortunately it's "the wrong way round": it would give us \\( \rho \\) if we knew V, whereas we want V, knowing \\( \rho \\). What we must do, then, is "invert" Poisson's equation. That's the program for this section, although I shall do it by roundabout means, beginning, as always, with a point charge at the origin.

The electric field is \\( \vec{E} = (1 / 4 \pi \epsilon_0)(1 / r^2) \vu{r} \\), and \\( \dd{\vec{l}} = \dd{r} \vu{r}  \\), and \\( \dd{\vec{l}} = \dd{r} \vu{r} + r \dd{\theta} \vu{\theta} + r \sin \theta \dd{\theta} \vu{\phi} \\), so

{{< katex display >}}
\vec{E} \cdot \dd{\vec{l}} = \frac{1}{4 \pi \epsilon_0} \frac{q}{r^2} \dd{r} 
{{< /katex >}}

Setting the reference point at infinity, the potential of a point charge _q_ at the origin is

{{< katex display >}}
V(r) = - \int_{\mathscr{O}} ^r \vec{E} \cdot \dd{\vec{l}} \\
 = \frac{-1}{4 \pi \epsilon_0} \int_{\infty}^r \frac{q}{(r') ^2} \dd{r'} \\
 = \left.\frac{1}{4 \pi \epsilon_0} \frac{q}{r'} \right| ^r _{\infty} = \frac{1}{4 \pi \epsilon_0} \frac{q}{r} 
{{< /katex >}}


(You see here the advantage of using infinity for the reference point: it kills the lower limit on the integral.) Notice the sign of V; presumably the conventional minus sign in the definition was chosen in order to make the potential of a positive charge come out positive. It is useful to remember that regions of positive charge are potential "hills," and electric field points "downhill" from plus toward minus.

<p align="center"> <img alt="Figure 2.32" src="/r/img/griffiths/2.32.png" /> </p>

In general, the potential of a point charge q is

{{< katex display >}}
V(\vec{r}) = \frac{1}{4 \pi \epsilon_0} \frac{q}{\gr} 
{{< /katex >}}


where \\( \gr \\), as always, is the distance from \\( q \\) to \\( \vec{r} \\) (Fig 2.32). Invoking the superposition principle, then, the potential of a collection of charges is 

{{< katex display >}}
V(r) = \frac{1}{4\pi \epsilon_0} \sum_{i=1} ^n \frac{q_i}{\gr _i} 
{{< /katex >}}

or, for a continuous distribution,

{{< katex display >}}
V(r) = \frac{1}{4 \pi \epsilon_0} \int \frac{\rho(\vec{r}')}{\gr} \dd{\tau'} \label{2.29} \tag{2.29}
{{< /katex >}}


This is the equation we were looking for, telling us how to compute V when we know \\( \rho \\); it is, if you like, the "solution" to Poisson's equation, for a localized charge distribution. Compare \\( \eqref{2.29} \\) with the corresponding formula for the electric field in terms of \\( \rho \\):

{{< katex display >}}
\vec{E}(\vec{r}) = \frac{1}{4 \pi \epsilon_0} \int \frac{\rho(\vec{r'})}{\gr ^2} \vu{\gr} \dd{\tau'}
{{< /katex >}}


The main point is that the pesky unit vector \\( \vu{\gr} \\) is gone, so there is no need to fuss with components. The potentials of line and surface charges are

{{< katex display >}}
V = \frac{1}{4 \pi \epsilon_0} \int \frac{\lambda(\vec{r'})}{\gr} \dd{l'} \qquad \text{ and } \qquad V = \frac{1}{4 \pi \epsilon_0} \int \frac{\sigma(\vec{r'})}{\gr} \dd{a'}
{{< /katex >}}


I should warn you that everything in this section is predicated on the assumption that the reference point is at infinity. This is hardly apparent in \\( \eqref{2.29} \\), but remember that we _got_ the equation from the potential of a point charge at the origin, \\( (1/4 \pi \epsilon_0) (q / r) \\), which is valid only when \\( \mathscr{O} = \infty \\). If you try to apply these formulas to one of those artificial problems in which the charge itself extends to infinity, the integral will diverge.

## 2.3.5: Boundary Conditions

In the typical electrostatic problem you are given a source charge distribution \\( \rho \\), and you want to find the electric field \\( \vec{E} \\) it produces. Unless the symmetry of the problem allows a solution by Gauss's law, it is generally to your advantage to calculate the potential first, as an intermediate step. These are the three fundamental quantities of electrostatics: \\( \rho \\), \\( \vec{E} \\), and \\( V \\). We have, in the course of our discussion, derived all six formulas interrelating them. These equations are neatly summarized in Fig. 2.35. We began with just two experimental observations: (1) the principle of superposition - a broad general rule applying to all electromagnetic forces, and (2) Coulomb's law - the fundamental law of electrostatics. From these, all else followed.

<p align="center"> <img alt="Figure 2.35" src="/r/img/griffiths/2.35.png" /> </p>

You may have noticed, in studying the exercises in this chapter, that the electric field always undergoes a discontinuity when you cross a surface charge \\( \sigma \\). In fact, it is a simple matter to find the _amount_ by which E changes at such a boundary. Suppose we draw a wafer-thin Gaussian pillbox, extending just barely over the edge in each direction (Fig. 2.36). Gauss's law says that

{{< katex display >}}
\oint _{S} \vec{E} \cdot \dd{\vec{a}} = \frac{1}{\epsilon_0} Q_{enc} = \frac{1}{\epsilon_0} \sigma A
{{< /katex >}}


<p align="center"> <img alt="Figure 2.36" src="/r/img/griffiths/2.36.png" /> </p>
where A is the area of the pillbox lid. If \\( \sigma \\)  varies from point to point or the surface is curved, we can simply pick A to be extremely small. Now, the sides of the pillbox contribute nothing to the flux, in the limit as the thickness \\( \epsilon \\)  goes to zero, so we are left with 

{{< katex display >}}
E_{above}^{\perp} - E_{below} ^{\perp} = \frac{1}{\epsilon_0} \sigma \label{2.31} \tag{2.31}
{{< /katex >}}

where \\( E_{above}^{\perp} \\) denotes the component of \\( \vec{E} \\) that is perpendicular to the surface immediately above, and \\(  E_{below} ^{\perp} \\) is the same, only just below the surface. For consistency, let "upward" be the positive direction for both. _Conclusion: the normal component of \\( \vec{E} \\) is discontinuous by an amount \\( \sigma / \epsilon_0 \\) at any boundary._ In particular, where there is _no_ surface charge, \\( \vec{E}^{\perp} \\) is continuous, as for instance at the surface of a uniformly charged solid sphere.

The _tangential_ component of \\( \vec{E} \\), by contrast, is always continuous. For if we apply Eq. 2.19,

{{< katex display >}}
\oint \vec{E} \cdot \dd{\vec{l}} = 0
{{< /katex >}}

to the thin rectangular loop of Fig 2.37, the ends give nothing (as \\( \epsilon \rightarrow 0 \\)), and the sides give \\( (E_{above} ^{\parallel} l - E_{below} ^{\parallel} l) \\), so

{{< katex display >}}
\vec{E}_{above} ^{\parallel} = \vec{E}_{below} ^{\parallel} \label{2.32} \tag{2.32}
{{< /katex >}}

where \\( \vec{E}^{\parallel} \\) stands for the components of \\( \vec{E} \\) parallel to the surface.

<p align="center"> <img alt="Figure 2.36" src="/r/img/griffiths/2.36.png" /> </p>

The boundary conditions on \\( \vec{E} \\) (Eqs. \\( \eqref{2.31} \\) and \\( \eqref{2.32} \\)) can be combined into a single formula:

{{< katex display >}}
\vec{E}_{above} - \vec{E}_{below} = \frac{\sigma}{\epsilon_0} \vu{n} \label{2.33}
{{< /katex >}}

where \\( \vu{n} \\) is a unit vector perpendicular to the surface, pointing from "below" to "above."

<p align="center"> <img alt="Figure 2.37" src="/r/img/griffiths/2.37.png" /> </p>
<p align="center"> <img alt="Figure 2.38" src="/r/img/griffiths/2.38.png" /> </p>

The potential, meanwhile, is continuous across any boundary (Fig 2.38), since

{{< katex display >}}
V_{above} - V_{below} = -\int_{a}^{b} \vec{E} \cdot \dd{\vec{l}}
{{< /katex >}}

as the path length shrinks to zero, so too does the integral

{{< katex display >}}
V_{above} = V_{below} \label{2.34} \tag{2.34}
{{< /katex >}}


However, the _gradient_ of V inherits the discontinuity in \\( \vec{E} \\), since \\( \vec{E} - \grad{V} \\), so

{{< katex display >}}
\grad{V}_{above} - \grad{V}_{below} = - \frac{\sigma}{\epsilon_0} \vu{n}
{{< /katex >}}

or more conveniently

{{< katex display >}}
\pdv{V_{above}}{n} - \pdv{V_{below}}{n} = - \frac{1}{\epsilon_0} \sigma \label{2.36} \tag{2.36}
{{< /katex >}}

where

{{< katex display >}}
\pdv{V}{n} = \grad{V} \cdot \vu{n}
{{< /katex >}}

denotes the normal derivative of V (that is, the rate of change in the direction perpendicular to the surface).

Please note that these boundary conditions relate the fields and potentials _just_ above and _just_ below the surface. For example, the derivatives in \\( \eqref{2.36} \\) are the limiting values as we approach the surface from either side. 
