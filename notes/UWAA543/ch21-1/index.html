<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="21.1 Finite Difference Algorithms# Definitions# By definition, Finite Differencing is a method to approximate partial differential equations which we cannot solve, into a system of algebraic equations which we can.
Notation to simplify our representations:
Superscripts: We use superscripts to denote steps in the time domain \( t^n = n \Delta t \). Here \( n = [0, N] \) is the step index and \( \Delta t \) is the time-step \( T/N \) Subscripts: \( x_j = j \Delta x \). Here \( j = [0, J] \) is the step index and \( \Delta x = L/J \) is the spatial step. Together: \( u_j ^n = u(t^n, x_j) \) Explicit algorithms: Use data that is already known at the present time to advance the solution to the next time step. They are easier and faster to implement, but they introduce stability constraints. \[ u_j ^{n+1} = f(u_j ^n, u_{j+1} ^n , u_{j+2} ^n \ldots) \] Implicit algorithms: Use data from the next time step when advancing the solution. Leads to a system of equations that must be solved simultaneously \[ u_{j} ^{n+1} = f(u_{j} ^n , u_{j+1} ^{n+1}, u_{j-1} ^{n+1}, \ldots) \] One look at the typical definition of the derivative suggests an algebraic approximation
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://peppyhare.github.io/r/notes/UWAA543/ch21-1/"><meta property="og:site_name" content="My Notes"><meta property="og:title" content="Finite Difference Algorithms"><meta property="og:description" content="21.1 Finite Difference Algorithms# Definitions# By definition, Finite Differencing is a method to approximate partial differential equations which we cannot solve, into a system of algebraic equations which we can.
Notation to simplify our representations:
Superscripts: We use superscripts to denote steps in the time domain \( t^n = n \Delta t \). Here \( n = [0, N] \) is the step index and \( \Delta t \) is the time-step \( T/N \) Subscripts: \( x_j = j \Delta x \). Here \( j = [0, J] \) is the step index and \( \Delta x = L/J \) is the spatial step. Together: \( u_j ^n = u(t^n, x_j) \) Explicit algorithms: Use data that is already known at the present time to advance the solution to the next time step. They are easier and faster to implement, but they introduce stability constraints. \[ u_j ^{n+1} = f(u_j ^n, u_{j+1} ^n , u_{j+2} ^n \ldots) \] Implicit algorithms: Use data from the next time step when advancing the solution. Leads to a system of equations that must be solved simultaneously \[ u_{j} ^{n+1} = f(u_{j} ^n , u_{j+1} ^{n+1}, u_{j-1} ^{n+1}, \ldots) \] One look at the typical definition of the derivative suggests an algebraic approximation"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:modified_time" content="2023-02-08T14:35:35-08:00"><meta itemprop=name content="Finite Difference Algorithms"><meta itemprop=description content="21.1 Finite Difference Algorithms# Definitions# By definition, Finite Differencing is a method to approximate partial differential equations which we cannot solve, into a system of algebraic equations which we can.
Notation to simplify our representations:
Superscripts: We use superscripts to denote steps in the time domain \( t^n = n \Delta t \). Here \( n = [0, N] \) is the step index and \( \Delta t \) is the time-step \( T/N \) Subscripts: \( x_j = j \Delta x \). Here \( j = [0, J] \) is the step index and \( \Delta x = L/J \) is the spatial step. Together: \( u_j ^n = u(t^n, x_j) \) Explicit algorithms: Use data that is already known at the present time to advance the solution to the next time step. They are easier and faster to implement, but they introduce stability constraints. \[ u_j ^{n+1} = f(u_j ^n, u_{j+1} ^n , u_{j+2} ^n \ldots) \] Implicit algorithms: Use data from the next time step when advancing the solution. Leads to a system of equations that must be solved simultaneously \[ u_{j} ^{n+1} = f(u_{j} ^n , u_{j+1} ^{n+1}, u_{j-1} ^{n+1}, \ldots) \] One look at the typical definition of the derivative suggests an algebraic approximation"><meta itemprop=dateModified content="2023-02-08T14:35:35-08:00"><meta itemprop=wordCount content="2024"><title>Finite Difference Algorithms | My Notes</title><link rel=icon href=/r/favicon.png><link rel=manifest href=/r/manifest.json><link rel=canonical href=https://peppyhare.github.io/r/notes/UWAA543/ch21-1/><link rel=stylesheet href=/r/book.min.bff56aeef7242395ec77303d273e044b6e6131a5e670ccb81dfa0f44a300fae2.css integrity="sha256-v/Vq7vckI5XsdzA9Jz4ES25hMaXmcMy4HfoPRKMA+uI=" crossorigin=anonymous><script defer src=/r/fuse.min.js></script><script defer src=/r/en.search.min.09e08103b88c7cae84b8b4e9ec43abbb0af0828a505fe97263f338600d986389.js integrity="sha256-CeCBA7iMfK6EuLTp7EOruwrwgopQX+lyY/M4YA2YY4k=" crossorigin=anonymous></script><script defer src=/r/sw.min.9e3a83f0b071ebe0141a16a33db93faadb2bdf712473a218febeed35ed243c08.js integrity="sha256-njqD8LBx6+AUGhajPbk/qtsr33Ekc6IY/r7tNe0kPAg=" crossorigin=anonymous></script><link rel=preload href=/r/katex/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Main-Bold.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Main-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Size3-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/fonts/roboto-v27-latin-regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/fonts/roboto-v27-latin-700.woff2 as=font type=font/woff2 crossorigin=anonymous></head><body dir=ltr class="book-kind-page book-type-notes"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/r/><span>My Notes</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul class=book-languages><li><input type=checkbox id=languages class=toggle>
<label for=languages class=flex><a role=button><img src=/r/icons/translate.svg class=book-icon alt=Languages>
English
</a><img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul><ul><li class=book-section-flat><a>Notes</a><ul><li class=book-section-flat><input type=checkbox id=section-f04c181c9b16a37431fe06303d58b7a0 class=toggle>
<label for=section-f04c181c9b16a37431fe06303d58b7a0 class=flex><a href=/r/notes/UWAA545/>Computational Methods For Plasmas</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/UWAA545/01-syllabus/>Syllabus</a></li><li><a href=/r/notes/UWAA545/02-plasma-models/>Plasma Models</a></li><li><a href=/r/notes/UWAA545/03-pic-method/>Particle in Cell Model</a></li><li><a href=/r/notes/UWAA545/04-pic-example/>PIC - Example Implementation</a></li><li><a href=/r/notes/UWAA545/05-electrodynamic-pic/>Multidimensional Electrodynamic PIC</a></li><li><a href=/r/notes/UWAA545/06-fluid-models/>Fluid Models for Plasmas</a></li><li><a href=/r/notes/UWAA545/07-finite-difference-models/>Finite Difference Methods for MHD</a></li><li><a href=/r/notes/UWAA545/08-mhd-equilibrium/>MHD Equilibrium Calculations</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-b6bdf3598cf4214623cd2f8ff7b6e0f2 class=toggle>
<label for=section-b6bdf3598cf4214623cd2f8ff7b6e0f2 class=flex><a href=/r/notes/UWAA560/>Plasma Diagnostics</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/UWAA560/01-syllabus/>Syllabus</a></li><li><a href=/r/notes/UWAA560/02-diagnostic-considerations/>General Diagnostic Considerations</a></li><li><a href=/r/notes/UWAA560/03-magnetic-field-diagnostics/>Magnetic Field Diagnostics</a></li><li><a href=/r/notes/UWAA560/04-electrostatic-diagnostics/>Electrostatic Diagnostics</a></li><li><a href=/r/notes/UWAA560/05-index-of-refraction-measurements/>Index of Refraction Measurements</a></li><li><a href=/r/notes/UWAA560/06-spectroscopic-measurements/>Spectroscopic Measurements</a></li><li><a href=/r/notes/UWAA560/90-student-lectures/>Student Lectures</a></li><li><a href=/r/notes/UWAA560/91-zeeman-spectroscopy/>My class lecture</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-5b051410be8cdb0f46ad32fc2ad5a20d class=toggle>
<label for=section-5b051410be8cdb0f46ad32fc2ad5a20d class=flex><a href=/r/notes/UWAA558/>MHD Theory</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/UWAA558/01-syllabus/>Syllabus</a></li><li><a href=/r/notes/UWAA558/02-plasma-models/>Plasma Models</a></li><li><a href=/r/notes/UWAA558/03-plasma-fluid-model/>Plasma Fluid Model</a></li><li><a href=/r/notes/UWAA558/04-two-fluid-plasma-model/>Two-Fluid Plasma Model</a></li><li><a href=/r/notes/UWAA558/05-mhd-model/>Magnetohydrodynamic (MHD) Model</a></li><li><a href=/r/notes/UWAA558/06-boundary-conditions/>Boundary Conditions</a></li><li><a href=/r/notes/UWAA558/07-equilibrium-for-fusion/>Equilibrium for Fusion</a></li><li><a href=/r/notes/UWAA558/08-1d-equilibria/>1-D Equilibria</a></li><li><a href=/r/notes/UWAA558/09-2d-equilibria/>2D Equilibria</a></li><li><a href=/r/notes/UWAA558/10-equilibrium-of-3d-configurations/>Equilibrium of 3D Configurations</a></li><li><a href=/r/notes/UWAA558/11-mhd-stability/>MHD Stability</a></li><li><a href=/r/notes/UWAA558/formulary/>Formulary</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-c3201a1057283cb12ab09a42fe89bfb2 class=toggle>
<label for=section-c3201a1057283cb12ab09a42fe89bfb2 class=flex><a href=/r/notes/research/>Research Notes</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/research/apollo/>Apollo dynamic tuning framework for RAJA</a></li><li><a href=/r/notes/research/dgh-datta/>Electrodynamic Dory-Guest-Harris Instability</a></li><li><a href=/r/notes/research/install-tricks/>Installation tricks</a></li><li><a href=/r/notes/research/valgrind/>Valgrind</a></li><li><a href=/r/notes/research/warpxm-101/>WARPXM 101 - Getting Started</a></li><li><a href=/r/notes/research/warpxm-102/>WARPXM 102 - Code Structure</a></li><li><a href=/r/notes/research/warpxm-201/>WARPXM 201 - Unstructured Geometry</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-e5101c35c8277102365bd86ab3e99a0d class=toggle>
<label for=section-e5101c35c8277102365bd86ab3e99a0d class=flex><a href=/r/notes/UWAMATH567/>Applied Complex Analysis</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/UWAMATH567/01-overview/>Overview</a></li><li><a href=/r/notes/UWAMATH567/02-complex-numbers/>Complex Numbers</a></li><li><a href=/r/notes/UWAMATH567/03-analytic-functions/>Analytic Functions and Integration</a></li><li><a href=/r/notes/UWAMATH567/04-series/>Sequences, series, and singularities</a></li><li><a href=/r/notes/UWAMATH567/05-residue-calculus/>Residue calculus and applications of contour integration</a></li><li><a href=/r/notes/UWAMATH567/06-real-integrals/>Real Integrals</a></li><li><a href=/r/notes/UWAMATH567/07-integrals-of-multivalued-functions/>Integrals of Multivalued Functions</a></li><li><a href=/r/notes/UWAMATH567/08-fourier-transform/>Fourier Transforms and Laplace Transforms</a></li><li><a href=/r/notes/UWAMATH567/09-conformal-mapping/>Conformal Mappings</a></li><li><a href=/r/notes/UWAMATH567/10-fluid-flow/>Fluid Flow</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-34991d35561e8d266d64d5d323e97c7a class=toggle>
<label for=section-34991d35561e8d266d64d5d323e97c7a class=flex><a href=/r/notes/UWAA557/>Physics of Fusion Plasmas</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/UWAA557/ch10-0/>Rules of thumb</a></li><li><a href=/r/notes/UWAA557/ch10-1/>Statistical Mechanics</a></li><li><a href=/r/notes/UWAA557/ch10-2/>Review of E&amp;M</a></li><li><a href=/r/notes/UWAA557/ch10-3/>Lagrange Multipliers</a></li><li><a href=/r/notes/UWAA557/ch11-1/>Wall-supported Plasma</a></li><li><a href=/r/notes/UWAA557/ch11-2/>Collisions</a></li><li><a href=/r/notes/UWAA557/ch11-3/>Oscillations</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-7c7b4e4d4494a744744faedd969cb670 class=toggle checked>
<label for=section-7c7b4e4d4494a744744faedd969cb670 class=flex><a href=/r/notes/UWAA543/>Computational CFD</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/UWAA543/ch20-1/>Introduction to Computational CFD</a></li><li><a href=/r/notes/UWAA543/ch20-2/>Governing Equations</a></li><li><a href=/r/notes/UWAA543/ch20-3/>Reduced Models</a></li><li><a href=/r/notes/UWAA543/ch20-4/>Equation Types</a></li><li><a href=/r/notes/UWAA543/ch20-5/>Panel Method</a></li><li><a href=/r/notes/UWAA543/ch21-1/ class=active>Finite Difference Algorithms</a></li><li><a href=/r/notes/UWAA543/ch21-2/>Explicit Finite Difference Algorithms</a></li><li><a href=/r/notes/UWAA543/ch21-3/>Finite Difference and Finite Volume Methods</a></li><li><a href=/r/notes/UWAA543/ch21-4/>Implicit Algorithms</a></li><li><a href=/r/notes/UWAA543/ch21-5/>Numerical Boundary Conditions</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-e5f141895443fc824f58730f7904d483 class=toggle>
<label for=section-e5f141895443fc824f58730f7904d483 class=flex><a href=/r/notes/UWAA556/>Plasma Waves</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/UWAA556/ch01-1/>Mathematical review</a></li><li><a href=/r/notes/UWAA556/ch02-1/>Plasma Waves in General Dielectric Media</a></li><li><a href=/r/notes/UWAA556/ch02-2/>Wave Properties in Cold Unmagnetized Plasma</a></li><li><a href=/r/notes/UWAA556/ch02-3/>Cold Magnetized Plasma Dispersion Relation</a></li><li><a href=/r/notes/UWAA556/ch02-4/>The CMA Diagram</a></li><li><a href=/r/notes/UWAA556/ch03-1/>Introduction to Kinetic Theory</a></li><li><a href=/r/notes/UWAA556/ch03-2/>Landau Damping</a></li><li><a href=/r/notes/UWAA556/ch03-3/>Waves in Hot Magnetized Plasma</a></li><li><a href=/r/notes/UWAA556/ch04-1/>Fluid stuff</a></li><li><a href=/r/notes/UWAA556/ch04-2/>Quasi-Linear Theory</a></li><li><a href=/r/notes/UWAA556/ch05-1/>Diffusion and Resistivity</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-3a2759a8b11b3422da800ed19897932a class=toggle>
<label for=section-3a2759a8b11b3422da800ed19897932a class=flex><a href=/r/notes/problems/>Worked Problems</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/problems/gurnett/ch02/>Characteristic Parameters of a Plasma</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-05ac7760b68f0e0530d0e609833f6902 class=toggle>
<label for=section-05ac7760b68f0e0530d0e609833f6902 class=flex><a role=button>Scratch</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/scratch/colors/>Adding Color</a></li><li><a href=/r/notes/scratch/crews2018/>Crews (2018)</a></li><li><a href=/r/notes/scratch/datta2021/>Datta (2021)</a></li><li><a href=/r/notes/scratch/drawing/>Drawing Diagrams</a></li><li><a href=/r/notes/scratch/goedbloed/>Goedbloed (2019)</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-c8688d5789736c2ae128963cf705a441 class=toggle>
<label for=section-c8688d5789736c2ae128963cf705a441 class=flex><a href=/r/notes/griffiths/>Griffiths Introduction to Electrodynamics</a>
<img src=/r/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/r/notes/griffiths/ch1-1/>(1.1) Vector Algebra</a></li><li><a href=/r/notes/griffiths/ch1-2/>(1.2) Differential Calculus</a></li><li><a href=/r/notes/griffiths/ch1-3/>(1.3) Integral Calculus</a></li><li><a href=/r/notes/griffiths/ch1-4/>(1.4) Curvilinear Coordinates</a></li><li><a href=/r/notes/griffiths/ch1-5/>(1.5) The Dirac Delta Function</a></li><li><a href=/r/notes/griffiths/ch1-6/>(1.6) The Theory of Vector Fields</a></li><li><a href=/r/notes/griffiths/ch2-1/>(2.1) The Electric Field</a></li><li><a href=/r/notes/griffiths/ch2-2/>(2.2) Divergence and Curl of Electrostatic Fields</a></li><li><a href=/r/notes/griffiths/ch2-3/>(2.3) Electric Potential</a></li><li><a href=/r/notes/griffiths/ch2-4/>(2.4) Work and Energy in Electrostatics</a></li><li><a href=/r/notes/griffiths/ch2-5/>(2.5) Conductors</a></li><li><a href=/r/notes/griffiths/ch3-1/>(3.1) Laplace's Equation</a></li><li><a href=/r/notes/griffiths/ch3-2/>(3.2) The Method of Images</a></li><li><a href=/r/notes/griffiths/ch3-3/>(3.3) Separation of Variables</a></li><li><a href=/r/notes/griffiths/ch3-4/>(3.4) Multipole Expansion</a></li><li><a href=/r/notes/griffiths/ch4-1/>(4.1) Polarization</a></li><li><a href=/r/notes/griffiths/ch4-2/>(4.2) The Field of a Polarized Object</a></li><li><a href=/r/notes/griffiths/ch4-3/>(4.3) The Electric Displacement</a></li><li><a href=/r/notes/griffiths/ch4-4/>(4.4) The Linear Dielectrics</a></li><li><a href=/r/notes/griffiths/ch5-1/>(5.1) The Lorentz Force Law</a></li><li><a href=/r/notes/griffiths/ch5-2/>(5.2) The Biot-Savart Law</a></li><li><a href=/r/notes/griffiths/ch5-3/>(5.3) The Divergence and Curl of B</a></li><li><a href=/r/notes/griffiths/ch5-4/>(5.4) Magnetic Vector Potential</a></li><li><a href=/r/notes/griffiths/ch6-1/>(6.1) Magnetization</a></li><li><a href=/r/notes/griffiths/ch6-2/>(6.2) The Field of a Magnetized Object</a></li><li><a href=/r/notes/griffiths/ch6-3/>(6.3) The Auxiliary Field H</a></li><li><a href=/r/notes/griffiths/ch6-4/>(6.4) Linear and Nonlinear Media</a></li><li><a href=/r/notes/griffiths/ch7-1/>(7.1) Electromotive Force</a></li><li><a href=/r/notes/griffiths/ch7-2/>(7.2) Electromagnetic Induction</a></li><li><a href=/r/notes/griffiths/ch7-3/>(7.3) Maxwell's Equations</a></li><li><a href=/r/notes/griffiths/ch8-0/>(8.0) Phys 544 Introduction</a></li><li><a href=/r/notes/griffiths/ch8-1/>(8.1) Charge and Energy</a></li><li><a href=/r/notes/griffiths/ch8-2/>(8.2) Momentum</a></li><li><a href=/r/notes/griffiths/ch9-1/>(9.1) Electromagnetic Waves in One Dimension</a></li><li><a href=/r/notes/griffiths/ch9-2/>(9.2) Wave Equation for E and B</a></li><li><a href=/r/notes/griffiths/ch9-3/>(9.3) Electromagnetic Waves in Matter</a></li><li><a href=/r/notes/griffiths/ch9-4/>(9.4) Electromagnetic Waves in Conductors</a></li><li><a href=/r/notes/griffiths/ch9-5/>(9.5) Guided Waves</a></li><li><a href=/r/notes/griffiths/ch10-1/>(10.1) Scalar and Vector Potentials</a></li><li><a href=/r/notes/griffiths/ch10-2/>(10.2) Retarded Potentials</a></li><li><a href=/r/notes/griffiths/ch10-3/>(10.3) Point Charges</a></li><li><a href=/r/notes/griffiths/ch11-1/>(11.1) Dipole Radiation</a></li><li><a href=/r/notes/griffiths/problems-ch3/>Solved Problems Ch3</a></li><li><a href=/r/notes/griffiths/problems-ch5/>Solved Problems Ch5</a></li><li><a href=/r/notes/griffiths/problems-ch7/>Solved Problems Ch7</a></li><li><a href=/r/notes/griffiths/problems-ch9/>Solved Problems Ch9</a></li></ul></li></ul></li></ul><ul class=book-menu-hugo><li><a href=https://github.com/Peppyhare/r target=_blank rel=noopener>Github</a></li><li><a href=https://themes.gohugo.io/hugo-book/ target=_blank rel=noopener>Hugo Themes</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/r/icons/menu.svg class=book-icon alt=Menu></label><h3>Finite Difference Algorithms</h3><label for=toc-control><img src=/r/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#211-finite-difference-algorithms>21.1 Finite Difference Algorithms</a><ul><li><a href=#definitions>Definitions</a></li><li><a href=#accuracy>Accuracy</a></li><li><a href=#algorithm-requirements>Algorithm Requirements</a><ul><li><a href=#consistency>Consistency</a></li><li><a href=#stability>Stability</a></li><li><a href=#convergence>Convergence</a></li><li><a href=#accuracy-1>Accuracy</a></li><li><a href=#sources-of-errors>Sources of Errors?</a></li></ul></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=211-finite-difference-algorithms>21.1 Finite Difference Algorithms<a class=anchor href=#211-finite-difference-algorithms>#</a></h1><h2 id=definitions>Definitions<a class=anchor href=#definitions>#</a></h2><p>By definition, <strong>Finite Differencing</strong> is a method to <em>approximate</em> partial differential equations which we cannot solve, into a system of algebraic equations which we can.</p><p>Notation to simplify our representations:</p><ul><li>Superscripts: We use superscripts to denote steps in the time domain \( t^n = n \Delta t \). Here \( n = [0, N] \) is the step index and \( \Delta t \) is the time-step \( T/N \)</li><li>Subscripts: \( x_j = j \Delta x \). Here \( j = [0, J] \) is the step index and \( \Delta x = L/J \) is the spatial step.</li><li>Together: \( u_j ^n = u(t^n, x_j) \)</li><li><strong>Explicit</strong> algorithms: Use data that is already known at the present time to advance the solution to the next time step. They are easier and faster to implement, but they introduce stability constraints.</li></ul><link rel=stylesheet href=/r/katex/katex.min.css><script defer src=/r/katex/katex.min.js></script><script defer src=/r/katex/auto-render.min.js onload=loadKatex()></script><script>function loadKatex(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,trust:e=>["\\htmlId","\\href"].includes(e.command),macros:{"\\lcm":"\\mathop{\\mathrm{lcm}}","\\sen":"\\text{sen}\\,","\\dd":"\\mathop{\\mathrm{d} #1}","\\abs":"\\lvert #1 \\rvert","\\dd":"\\text{d}","\\cross":"\\times","\\pdv":"\\frac{\\partial #1}{\\partial #2}","\\curl":`\\nabla \\cross #1`,"\\vu":"\\mathbf{\\hat{#1}}","\\vdot":"\\dot","\\div":`\\nabla \\cdot #1`,"\\grad":`\\nabla`,"\\dv":"\\frac{d\\,#1}{d\\,#2}","\\gr":"\\gamma","\\vec":"\\mathbf{#1}","\\tagl":"\\tag{#1}","\\eqref":"(#1)","\\laplacian":`\\mathbf{\\nabla ^2}`,"\\label":"{}","\\negadelta":`\\nabla`,"\\eqref":"\\href{###1}{(\\text{#1})}","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}"}})}</script><span>\[ u_j ^{n+1} = f(u_j ^n, u_{j+1} ^n , u_{j+2} ^n \ldots)
\]</span><ul><li><strong>Implicit</strong> algorithms: Use data from the next time step when advancing the solution. Leads to a system of equations that must be solved simultaneously</li></ul><span>\[ u_{j} ^{n+1} = f(u_{j} ^n , u_{j+1} ^{n+1}, u_{j-1} ^{n+1}, \ldots)
\]</span><p>One look at the typical definition of the derivative suggests an algebraic approximation</p><span>\[\dv{f}{x} = \lim_{\Delta x \rightarrow 0} \frac{f(x + \Delta x) - f(x)}{\Delta x} \quad \rightarrow \quad \dv{f}{x} \approx \frac{f(x + \Delta x) - f(x) }{\Delta x}\]</span><p>Applying to our model equation, the linear advection equation</p><span>\[\pdv{u}{t} + c \pdv{u}{x} = 0\]</span><p>The first-order forward difference approximation for the temporal derivative is</p><span>\[\pdv{u}{t} \approx \frac{u_j ^{n+1} - u_j ^n}{\Delta t} \equiv \Delta _t u\]</span><p>And the first-order backward approximation for \( \pdv{u}{x} \) is</p><span>\[\pdv{u}{x} \approx \frac{u_{j} ^n - u_{j-1} ^n}{\Delta x} \equiv \nabla _x u\]</span><p>These are sometimes called Euler differencing, since they are first-order. Plugging in our approximations, we arrive at the &ldquo;Forward Euler Algorithm&rdquo;</p><span>\[\frac{u_{j} ^{n+1} u_j ^n}{\Delta t} + c \frac{u_{j} ^n - u_{j-1} ^n}{\Delta x} = 0\]</span><p>This is an explicit scheme: solve for \( u^{n+1} _j \)</p><span>\[u_j ^{n+1} = u_j ^n - \frac{c \Delta t}{\Delta x} (u_j ^n - u_{j-1} ^n)\]</span><p>The multiplier out front \( \frac{c \Delta t}{\Delta x} \) is very important for stability, so we call it</p><span>\[\frac{c \Delta t}{\Delta x} = \text{ Courant number (or CFL number)}\]</span><p>For the problem to be mathematically well-posed, we must know initial conditions and boundary conditions</p><span>\[u(t = 0, j) \qquad u(t, x = 0)\]</span><h2 id=accuracy>Accuracy<a class=anchor href=#accuracy>#</a></h2><p>We can be more precise with the error in our difference approximation: the error will be on the order of \( \Delta x \):</p><span>\[\dv{f}{x} \approx \frac{f(x + \Delta x) - f(x) }{\Delta x}\]
</span><span>\[\rightarrow \dv{f}{x} = \frac{f(x + \Delta x) - f(x) }{\Delta x} + O(\Delta x)\]</span><p>As it turns out, we can improve the accuracy of the finite difference operators by using centered differences:</p><span>\[\left. \pdv{u}{x} \right|_{j} = \frac{u_{j+1} ^n - u_{j-1} ^n}{2 \Delta x} + O(\Delta x ^2)\]</span><p>So the forward-time, centered-space (FTCS) PDE becomes</p><span>\[\frac{u_j ^{n+1} - u_j ^n}{\Delta t} + c \frac{u_{j+1} ^n - u_{j-1} ^n }{2 \Delta x} = 0\]</span><p>This is more accurate than the Euler method in space. We can write the accuracy as \( O(\Delta t, \Delta x^2) \), or &ldquo;it is first-order accurate in time and second-order accurate in space.&rdquo;</p><p>How do we get accuracy estimates? The accuracy is defined by using a Taylor series expansion for the finite-difference operators:</p><span>\[u_j ^{n+1} = u_j ^n + \pdv{u}{t} \Delta t + \frac{1}{2} \pdv{ ^2 u}{t^2} \Delta t^2 + \frac{1}{6} \pdv{ ^3 u}{t ^3} \Delta t^3 + \ldots\]
</span><span>\[u_{j+1} ^n = u_j ^n + \pdv{u}{x} \Delta x + \frac{1}{2} \pdv{ ^2 u}{x^2} \Delta x^2 + \frac{1}{6} \pdv{ ^3 u }{x ^3} \Delta x ^3 + \ldots\]
</span><span>\[u_{j-1} ^n = u_j ^n - \pdv{u}{x} \Delta x + \frac{1}{2} \pdv{ ^2 u }{x^2} \Delta x^2 - \frac{1}{6} \pdv{^3 u }{x^3} \Delta x ^3 + \ldots \]</span><p>Substituting into the Forward Euler algorithm:</p><span>\[u_j ^n + \pdv{u}{t} \Delta t + \frac{1}{2} \pdv{^2 u }{t^2} \Delta t^2 + \frac{1}{6} \pdv{ ^3 u}{t ^3} \Delta t^3 + \ldots\]
</span><span>\[= u_j ^n - \frac{c \Delta t}{\Delta x} \left( u_j ^n - \left[ u_j ^n - \pdv{u}{x} \Delta x + \pdv{^2 u }{x^2} \frac{\Delta x ^2}{2} \pm \ldots \right] \right)\]</span><p>After simplifying and re-arranging/canceling like terms, we get</p><span>\[\pdv{u}{t} + c \pdv{u}{x} = - \frac{1}{2} \pdv{^2 u}{t^2} \Delta t - \frac{1}{6} \Delta t^2 + \ldots + \frac{c}{2} \pdv{^2 u}{x^2} \Delta x - \frac{c}{6} \pdv{ ^3 u }{x ^3} \Delta x ^2 + \ldots\]</span><p>The left-hand side is the PDE we&rsquo;re trying to solve, so everything on the right-hand side is the error term introduced by our approximation. The solution we&rsquo;re going to get is actually the solution to the modified PDE with all of the error terms. Reading off the lowest-order terms of \( \Delta x \) and \( \Delta t \) we see that the algorithm is first-order accurate in space and time.</p><h2 id=algorithm-requirements>Algorithm Requirements<a class=anchor href=#algorithm-requirements>#</a></h2><p>For an algorithm to work, it requires the following properties:</p><ol><li><strong>Consistency</strong>: Whatever finite difference operator \( \delta_x u \) we use, applied to our solution, has to approximate the derivative as the spacing goes to zero</li></ol><span>\[ \delta _x u \rightarrow \pdv{u}{x} \quad \text{ as } \quad \Delta x \rightarrow 0
\]</span><ol start=2><li><strong>Stability</strong>: The solution must be bounded, so for some initial condition \( u \) the norm goes to zero as the number of points goes to infinity</li></ol><span>\[ |u_j - u| \rightarrow 0 \quad \text{ as } \quad I \rightarrow \infty
\]</span><ol start=3><li><strong>Accuracy</strong>: The accuracy is bounded by the finite difference operator</li></ol><span>\[ \pdv{u}{x} - \delta _x u = O(\Delta x ^m)
\]</span><ol start=4><li><strong>Convergence</strong>: The numerical solution must approach the exact solution as the grid spacing goes to zero</li></ol><span>\[ u_j \rightarrow u \quad \text{ as } \quad \Delta x \rightarrow 0
\]</span><p>A useful theorem is Lax&rsquo;s Theorem: <em>An algorithm that is consistent and stable will converge</em>. This means that we only have to prove consistency, stability, and accuracy.</p><h3 id=consistency>Consistency<a class=anchor href=#consistency>#</a></h3><p>Let&rsquo;s take our Forward Euler algorithm as an example: From analyzing the accuracy, we derived the modified PDE and noted the leading-order error terms. Forward Euler gave \( O(\Delta x, \Delta t) \). As \( \Delta t, \Delta x \rightarrow 0 \), we recover the original PDE. Therefore, FE is consistent.</p><p>Likewise the FTCS is also consistent, since \( \Delta t, \Delta x \rightarrow 0 \) also recovers the original PDE. In fact, because the accuracy of FTCS was \( O(\Delta x ^2, \Delta t) \) it is also consistent.</p><h3 id=stability>Stability<a class=anchor href=#stability>#</a></h3><p>The way to perform the stability analysis is to use Fourier transforms to convert from a discrete spatial domain to a continuous frequency domain. Broadly speaking, the mathematical tools we have at our disposal to analyze stability only apply to continuous functions - you can&rsquo;t take a derivative of a set of discrete points. By transforming to a continuous domain, we can use properties of our basis functions to examine the growth of errors over time. This process is called <strong>Von Neumann Stability Analysis</strong>.</p><p>Example: Stability analysis of FTCS</p><span>\[u_j ^{n+1} = u_j ^n - \frac{a \Delta t}{2 \Delta x} \left( u_{j+1} ^n - u_{j-1} ^n \right)\]</span><p>We define an error norm by subtracting the exact solution</p><span>\[\varepsilon_j ^n = u_j ^n - \overline{u}\]
</span><span>\[\varepsilon_j ^{n+1} = \varepsilon_j ^n - \frac{a \Delta t}{2 \Delta x} \left( \varepsilon_{j+1} ^n - \varepsilon_{j-1} ^n \right)\]</span><p>To study the evolution of the errors, apply a Fourier transform to get to frequency space:</p><span>\[\varepsilon_j ^n = V^n e^{ik_x x} = V^n e^{ik_x (j \Delta x)}\]
</span><span>\[V^n = \text{ wave amplitude}\]
</span><span>\[k = \text{ wavenumber } = \frac{2 \pi}{\lambda_x}\]</span><p>Substituting,</p><span>\[V^{n+1} e^{i k_x j \Delta x} = V^n e^{i k_x j \Delta x} - \frac{a \Delta t}{2 \Delta x} \left(V^n e^{i k_x (j+1) \Delta x } - V^n e^{i k_x (j-1) \Delta x} \right)\]
</span><span>\[\rightarrow \frac{V^{n+1}}{V_n} = 1 - \frac{a \Delta t}{2 \Delta x} \left( e^{i k_x \Delta x} - e^{ik_x \Delta x} \right)\]</span><p>The ratio \( V^{n+1}/V^n \) tells us how the amplitudes of the errors will evolve in time. We define the amplification factor \( G \)</p><span>\[G = \left| \frac{V^{n+1}}{V^n} \right|\]</span><p>For stability, we need the errors not to grow over time, so the Von Neumann stability criterion is:</p><span>\[G^m \leq 1 \quad \forall n\]</span><p>Continuing with our example</p><span>\[\frac{V^{n+1}}{V_n} = 1 - \frac{a \Delta t}{2 \Delta x} \left[ \cos (k_x \Delta x) + i \sin(k \Delta x) - \cos (-k_x \Delta x) - i \sin (- k_x \Delta x) \right]\]
</span><span>\[= 1 - i \frac{ a \Delta t}{\Delta x} \sin (k_x \Delta x)\]</span><p>To get the amplification factor, we need the norm</p><span>\[G = \left[ \left(1 - i \frac{ a \Delta t}{\Delta x} \sin (k_x \Delta x) \right) \left( 1 + i \frac{ a \Delta t}{\Delta x} \sin (k_x \Delta x)\right) \right] ^{1/2}\]
</span><span>\[= \sqrt{ 1 + \left( \frac{a \Delta t}{\Delta x} ^2 \sin ^2 (k_x \Delta x)\right)}\]</span><p>But that&rsquo;s always greater than 1! So FTCS is unconditionally unstable.</p><p>Performing the same analysis for Forward Euler, we get a stability condition:</p><span>\[0 \leq 1 + 2\frac{a \Delta t}{\Delta x} \left( \frac{a \Delta t}{ \Delta x} -1 \right) (1 - \cos (k_x \Delta x)) \leq 1\]</span><p align=center><img alt="Figure 20.4" src=/r/img/20.4.png></p><p>We can see that the CFL number must be</p><span>\[0 \leq \frac{a \Delta t}{\Delta x} \leq 1\]</span><p>Possible values of \( k_x \Delta x = \frac{2 \pi}{\lambda} \Delta x \) . The minimum of \( k_x \Delta x \) occurs at \( \lambda = \infty \), uniform error throughout the domain. This only occurs if the error is everywhere zero, since the boundary conditions are presumed accurate. In practice, the maximum wavelength is equal to twice the length of the domain</p><span>\[\lambda_{max} = 2L\]
</span><span>\[(k_x \Delta x)_{max} = \frac{\pi}{J-1}\]</span><p>The maximum of \( k_x \Delta x \) is for \( \lambda = 0 \), but this is not possible on a grid with finite grid points. The Nyquist limit tells us that \( \lambda_{min} = 2 \Delta x \). That means that</p><span>\[(k_x \Delta x)_{max} = \pi\]</span><p>When you violate a stability condition, what do we expect to see? The error growth is largest for the largest value of \( k_x \Delta x \), which corresponds to a wavelength equal to the grid spacing. In practice, that looks like errors that blow up from point to point.</p><h3 id=convergence>Convergence<a class=anchor href=#convergence>#</a></h3><p>We want to show that the numerical solution approaches the exact solution to the original PDE.</p><p>Lax&rsquo;s equivalence theorem states:</p><p>If an algorithm is consistent and stability requirements are satisfied, the numerical solution will converge to the solution of the original PDE.</p><p>This is why consistency and stability is so important; if you have both, then you have convergence, which tells you that the problem you&rsquo;re solving is the problem you are actually trying to solve.</p><h3 id=accuracy-1>Accuracy<a class=anchor href=#accuracy-1>#</a></h3><p>The solution exists at discrete locations for multiple variables, e.g \( \rho, p, u, v, \ldots \), so we want a convenient measure of solution accuracy.</p><p>The general p-norm is defined as</p><span>\[\text{p-norm} = L_p = \left[\sum_{j=1} ^J |z|^p \right]^{1/p}\]</span><p>In practice, the most common norms that we use are the 1, 2, or \( \infty \)-norms.</p><span>\[L_1 = \sum |z| \quad \text{(average)}\]
</span><span>\[L_2 = \left[ \sum |z|^2 \right]^{1/2} \quad \text{(variance)}\]
</span><span>\[L_{\infty} = \text{max}|z| \quad \text{(max-norm)}\]</span><p>In practice, the 2-norm is the most rigorous definition of the error. Specifically, we define the error norm in the form</p><span>\[\text{Error norm} = \left[ \sum_{j=1} ^{J} \Delta x ( \varepsilon) ^2 \right] ^{1/2} = \sqrt{\Delta x} || \varepsilon ||_2\]
</span><span>\[\varepsilon_j = u_j - \overline{u}\]</span><h3 id=sources-of-errors>Sources of Errors?<a class=anchor href=#sources-of-errors>#</a></h3><p>Where do errors come from? In order to reduce our model&rsquo;s error, we must first understand where the errors come from.</p><p><strong>Truncation errors</strong> - Result from the terms in the Taylor series difference approximation that are neglected. They can be reduced by using higher accuracy difference operators.</p><p><strong>Round-off errors</strong> - Result of the limited machine accuracy (accuracy of floating point representation). It can be reduced by using higher precision to store values, <em>or</em> by performing fewer calculations.</p><p><strong>Bugs</strong> - Don&rsquo;t have bugs. ha. ha. ha. But really, we can minimize programming errors through practices like good planning, good comments, etc.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/r/notes/UWAA543/ch20-5/ class="flex align-center"><img src=/r/icons/backward.svg class=book-icon alt=Backward>
<span>Panel Method</span>
</a></span><span><a href=/r/notes/UWAA543/ch21-2/ class="flex align-center"><span>Explicit Finite Difference Algorithms</span>
<img src=/r/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#211-finite-difference-algorithms>21.1 Finite Difference Algorithms</a><ul><li><a href=#definitions>Definitions</a></li><li><a href=#accuracy>Accuracy</a></li><li><a href=#algorithm-requirements>Algorithm Requirements</a><ul><li><a href=#consistency>Consistency</a></li><li><a href=#stability>Stability</a></li><li><a href=#convergence>Convergence</a></li><li><a href=#accuracy-1>Accuracy</a></li><li><a href=#sources-of-errors>Sources of Errors?</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>