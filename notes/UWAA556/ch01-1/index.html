<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="




  \[\]



  Mathematical review
  #

We&rsquo;re starting off with some mathematical foundation to ensure we&rsquo;re all on the same page before we start talking about waves and collisions."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://peppyhare.github.io/r/notes/UWAA556/ch01-1/"><meta property="og:site_name" content="My Notes"><meta property="og:title" content="Mathematical review"><meta property="og:description" content="\[\] Mathematical review # We’re starting off with some mathematical foundation to ensure we’re all on the same page before we start talking about waves and collisions."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:modified_time" content="2023-02-24T16:25:08-08:00"><title>Mathematical review | My Notes</title><link rel=icon href=/r/favicon.png><link rel=manifest href=/r/manifest.json><link rel=canonical href=https://peppyhare.github.io/r/notes/UWAA556/ch01-1/><link rel=stylesheet href=/r/book.min.a9f8198cc4e08a8c08b25f83e2006e5e66c64d3d34b7046b3e8712b7980c6821.css integrity="sha256-qfgZjMTgiowIsl+D4gBuXmbGTT00twRrPocSt5gMaCE=" crossorigin=anonymous><script defer src=/r/fuse.min.js></script><script defer src=/r/en.search.min.46849726e35b1b7f0c86d51481c0ee1295cbcfe03da553bde80e47b9b040a7e9.js integrity="sha256-RoSXJuNbG38MhtUUgcDuEpXLz+A9pVO96A5HubBAp+k=" crossorigin=anonymous></script><script defer src=/r/sw.min.9e3a83f0b071ebe0141a16a33db93faadb2bdf712473a218febeed35ed243c08.js integrity="sha256-njqD8LBx6+AUGhajPbk/qtsr33Ekc6IY/r7tNe0kPAg=" crossorigin=anonymous></script><link rel=preload href=/r/katex/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Main-Bold.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Main-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/katex/fonts/KaTeX_Size3-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/fonts/roboto-v27-latin-regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/r/fonts/roboto-v27-latin-700.woff2 as=font type=font/woff2 crossorigin=anonymous></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/r/><span>My Notes</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul class=book-languages><li><input type=checkbox id=languages class=toggle>
<label for=languages class="flex justify-between"><a role=button class="flex align-center"><img src=/r/svg/translate.svg class=book-icon alt=Languages>
English</a></label><ul></ul></li></ul><ul><li class=book-section-flat><ul><li class=book-section-flat><input type=checkbox id=section-f04c181c9b16a37431fe06303d58b7a0 class=toggle>
<label for=section-f04c181c9b16a37431fe06303d58b7a0 class="flex justify-between"><a href=/r/notes/UWAA545/ class="navbutton
book-collapse-section">Computational Methods For Plasmas</a></label><ul><li><a href=/r/notes/UWAA545/01-syllabus/ class=navbutton>Syllabus</a></li><li><a href=/r/notes/UWAA545/02-plasma-models/ class=navbutton>Plasma Models</a></li><li><a href=/r/notes/UWAA545/03-pic-method/ class=navbutton>Particle in Cell Model</a></li><li><a href=/r/notes/UWAA545/04-pic-example/ class=navbutton>PIC - Example Implementation</a></li><li><a href=/r/notes/UWAA545/05-electrodynamic-pic/ class=navbutton>Multidimensional Electrodynamic PIC</a></li><li><a href=/r/notes/UWAA545/06-fluid-models/ class=navbutton>Fluid Models for Plasmas</a></li><li><a href=/r/notes/UWAA545/07-finite-difference-models/ class=navbutton>Finite Difference Methods for MHD</a></li><li><a href=/r/notes/UWAA545/08-mhd-equilibrium/ class=navbutton>MHD Equilibrium Calculations</a></li><li><a href=/r/notes/UWAA545/formulary/ class=navbutton>Formulary</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-b6bdf3598cf4214623cd2f8ff7b6e0f2 class=toggle>
<label for=section-b6bdf3598cf4214623cd2f8ff7b6e0f2 class="flex justify-between"><a href=/r/notes/UWAA560/ class="navbutton
book-collapse-section">Plasma Diagnostics</a></label><ul><li><a href=/r/notes/UWAA560/01-syllabus/ class=navbutton>Syllabus</a></li><li><a href=/r/notes/UWAA560/02-diagnostic-considerations/ class=navbutton>General Diagnostic Considerations</a></li><li><a href=/r/notes/UWAA560/03-magnetic-field-diagnostics/ class=navbutton>Magnetic Field Diagnostics</a></li><li><a href=/r/notes/UWAA560/04-electrostatic-diagnostics/ class=navbutton>Electrostatic Diagnostics</a></li><li><a href=/r/notes/UWAA560/05-index-of-refraction-measurements/ class=navbutton>Index of Refraction Measurements</a></li><li><a href=/r/notes/UWAA560/06-spectroscopic-measurements/ class=navbutton>Spectroscopic Measurements</a></li><li><a href=/r/notes/UWAA560/90-student-lectures/ class=navbutton>Student Lectures</a></li><li><a href=/r/notes/UWAA560/91-zeeman-spectroscopy/ class=navbutton>My class lecture</a></li><li><a href=/r/notes/UWAA560/formulary/ class=navbutton>Formulary</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-5b051410be8cdb0f46ad32fc2ad5a20d class=toggle>
<label for=section-5b051410be8cdb0f46ad32fc2ad5a20d class="flex justify-between"><a href=/r/notes/UWAA558/ class="navbutton
book-collapse-section">MHD Theory</a></label><ul><li><a href=/r/notes/UWAA558/01-syllabus/ class=navbutton>Syllabus</a></li><li><a href=/r/notes/UWAA558/02-plasma-models/ class=navbutton>Plasma Models</a></li><li><a href=/r/notes/UWAA558/03-plasma-fluid-model/ class=navbutton>Plasma Fluid Model</a></li><li><a href=/r/notes/UWAA558/04-two-fluid-plasma-model/ class=navbutton>Two-Fluid Plasma Model</a></li><li><a href=/r/notes/UWAA558/05-mhd-model/ class=navbutton>Magnetohydrodynamic (MHD) Model</a></li><li><a href=/r/notes/UWAA558/06-boundary-conditions/ class=navbutton>Boundary Conditions</a></li><li><a href=/r/notes/UWAA558/07-equilibrium-for-fusion/ class=navbutton>Equilibrium for Fusion</a></li><li><a href=/r/notes/UWAA558/08-1d-equilibria/ class=navbutton>1-D Equilibria</a></li><li><a href=/r/notes/UWAA558/09-2d-equilibria/ class=navbutton>2D Equilibria</a></li><li><a href=/r/notes/UWAA558/10-equilibrium-of-3d-configurations/ class=navbutton>Equilibrium of 3D Configurations</a></li><li><a href=/r/notes/UWAA558/11-mhd-stability/ class=navbutton>MHD Stability</a></li><li><a href=/r/notes/UWAA558/formulary/ class=navbutton>Formulary</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-c3201a1057283cb12ab09a42fe89bfb2 class=toggle>
<label for=section-c3201a1057283cb12ab09a42fe89bfb2 class="flex justify-between"><a href=/r/notes/research/ class="navbutton
book-collapse-section">Research Notes</a></label><ul><li><a href=/r/notes/research/dgh-datta/ class=navbutton>Electrodynamic Dory-Guest-Harris Instability</a></li><li><a href=/r/notes/research/valgrind/ class=navbutton>Valgrind</a></li><li><a href=/r/notes/research/warpxm-101/ class=navbutton>WARPXM 101 - Getting Started</a></li><li><a href=/r/notes/research/warpxm-102/ class=navbutton>WARPXM 102 - Code Structure</a></li><li><a href=/r/notes/research/warpxm-201/ class=navbutton>WARPXM 201 - Unstructured Geometry</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-34991d35561e8d266d64d5d323e97c7a class=toggle>
<label for=section-34991d35561e8d266d64d5d323e97c7a class="flex justify-between"><a href=/r/notes/UWAA557/ class="navbutton
book-collapse-section">Physics of Fusion Plasmas</a></label><ul><li><a href=/r/notes/UWAA557/ch10-0/ class=navbutton>Rules of thumb</a></li><li><a href=/r/notes/UWAA557/ch10-1/ class=navbutton>Statistical Mechanics</a></li><li><a href=/r/notes/UWAA557/ch10-2/ class=navbutton>Review of E&amp;M</a></li><li><a href=/r/notes/UWAA557/ch10-3/ class=navbutton>Lagrange Multipliers</a></li><li><a href=/r/notes/UWAA557/ch11-1/ class=navbutton>Wall-supported Plasma</a></li><li><a href=/r/notes/UWAA557/ch11-2/ class=navbutton>Collisions</a></li><li><a href=/r/notes/UWAA557/ch11-3/ class=navbutton>Oscillations</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-7c7b4e4d4494a744744faedd969cb670 class=toggle>
<label for=section-7c7b4e4d4494a744744faedd969cb670 class="flex justify-between"><a href=/r/notes/UWAA543/ class="navbutton
book-collapse-section">Computational CFD</a></label><ul><li><a href=/r/notes/UWAA543/ch20-1/ class=navbutton>Introduction to Computational CFD</a></li><li><a href=/r/notes/UWAA543/ch20-2/ class=navbutton>Governing Equations</a></li><li><a href=/r/notes/UWAA543/ch20-3/ class=navbutton>Reduced Models</a></li><li><a href=/r/notes/UWAA543/ch20-4/ class=navbutton>Equation Types</a></li><li><a href=/r/notes/UWAA543/ch20-5/ class=navbutton>Panel Method</a></li><li><a href=/r/notes/UWAA543/ch21-1/ class=navbutton>Finite Difference Algorithms</a></li><li><a href=/r/notes/UWAA543/ch21-2/ class=navbutton>Explicit Finite Difference Algorithms</a></li><li><a href=/r/notes/UWAA543/ch21-3/ class=navbutton>Finite Difference and Finite Volume Methods</a></li><li><a href=/r/notes/UWAA543/ch21-4/ class=navbutton>Implicit Algorithms</a></li><li><a href=/r/notes/UWAA543/ch21-5/ class=navbutton>Numerical Boundary Conditions</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-e5f141895443fc824f58730f7904d483 class=toggle checked>
<label for=section-e5f141895443fc824f58730f7904d483 class="flex justify-between"><a href=/r/notes/UWAA556/ class="navbutton
book-collapse-section">Plasma Waves</a></label><ul><li><a href=/r/notes/UWAA556/ch01-1/ class="active navbutton">Mathematical review</a></li><li><a href=/r/notes/UWAA556/ch02-1/ class=navbutton>Plasma Waves in General Dielectric Media</a></li><li><a href=/r/notes/UWAA556/ch02-2/ class=navbutton>Wave Properties in Cold Unmagnetized Plasma</a></li><li><a href=/r/notes/UWAA556/ch02-3/ class=navbutton>Cold Magnetized Plasma Dispersion Relation</a></li><li><a href=/r/notes/UWAA556/ch02-4/ class=navbutton>The CMA Diagram</a></li><li><a href=/r/notes/UWAA556/ch03-1/ class=navbutton>Introduction to Kinetic Theory</a></li><li><a href=/r/notes/UWAA556/ch03-2/ class=navbutton>Landau Damping</a></li><li><a href=/r/notes/UWAA556/ch03-3/ class=navbutton>Waves in Hot Magnetized Plasma</a></li><li><a href=/r/notes/UWAA556/ch04-1/ class=navbutton>Fluid stuff</a></li><li><a href=/r/notes/UWAA556/ch04-2/ class=navbutton>Quasi-Linear Theory</a></li><li><a href=/r/notes/UWAA556/ch05-1/ class=navbutton>Diffusion and Resistivity</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-3a2759a8b11b3422da800ed19897932a class=toggle>
<label for=section-3a2759a8b11b3422da800ed19897932a class="flex justify-between"><a href=/r/notes/problems/ class="navbutton
book-collapse-section">Worked Problems</a></label><ul><li><a href=/r/notes/problems/gurnett/ch02/ class=navbutton>Characteristic Parameters of a Plasma</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-05ac7760b68f0e0530d0e609833f6902 class=toggle>
<label for=section-05ac7760b68f0e0530d0e609833f6902 class="flex justify-between"><a role=button class="navbutton
book-collapse-section">Scratch</a></label><ul><li><a href=/r/notes/scratch/colors/ class=navbutton>Adding Color</a></li><li><a href=/r/notes/scratch/crews2018/ class=navbutton>Crews (2018)</a></li><li><a href=/r/notes/scratch/datta2021/ class=navbutton>Datta (2021)</a></li><li><a href=/r/notes/scratch/drawing/ class=navbutton>Drawing Diagrams</a></li><li><a href=/r/notes/scratch/goedbloed/ class=navbutton>Goedbloed (2019)</a></li></ul></li><li class=book-section-flat><input type=checkbox id=section-c8688d5789736c2ae128963cf705a441 class=toggle>
<label for=section-c8688d5789736c2ae128963cf705a441 class="flex justify-between"><a href=/r/notes/griffiths/ class="navbutton
book-collapse-section">Griffiths Introduction to Electrodynamics</a></label><ul><li><a href=/r/notes/griffiths/ch1-1/ class=navbutton>Vector Algebra</a></li><li><a href=/r/notes/griffiths/ch1-2/ class=navbutton>Differential Calculus</a></li><li><a href=/r/notes/griffiths/ch1-3/ class=navbutton>Integral Calculus</a></li><li><a href=/r/notes/griffiths/ch1-4/ class=navbutton>Curvilinear Coordinates</a></li><li><a href=/r/notes/griffiths/ch1-5/ class=navbutton>The Dirac Delta Function</a></li><li><a href=/r/notes/griffiths/ch1-6/ class=navbutton>The Theory of Vector Fields</a></li><li><a href=/r/notes/griffiths/ch2-1/ class=navbutton>The Electric Field</a></li><li><a href=/r/notes/griffiths/ch2-2/ class=navbutton>Divergence and Curl of Electrostatic Fields</a></li><li><a href=/r/notes/griffiths/ch2-3/ class=navbutton>Electric Potential</a></li><li><a href=/r/notes/griffiths/ch2-4/ class=navbutton>Work and Energy in Electrostatics</a></li><li><a href=/r/notes/griffiths/ch2-5/ class=navbutton>Conductors</a></li><li><a href=/r/notes/griffiths/ch3-1/ class=navbutton>Laplace's Equation</a></li><li><a href=/r/notes/griffiths/ch3-2/ class=navbutton>The Method of Images</a></li><li><a href=/r/notes/griffiths/ch3-3/ class=navbutton>Separation of Variables</a></li><li><a href=/r/notes/griffiths/ch3-4/ class=navbutton>Multipole Expansion</a></li><li><a href=/r/notes/griffiths/ch4-1/ class=navbutton>Polarization</a></li><li><a href=/r/notes/griffiths/ch4-2/ class=navbutton>The Field of a Polarized Object</a></li><li><a href=/r/notes/griffiths/ch4-3/ class=navbutton>The Electric Displacement</a></li><li><a href=/r/notes/griffiths/ch4-4/ class=navbutton>The Linear Dielectrics</a></li><li><a href=/r/notes/griffiths/ch5-1/ class=navbutton>The Lorentz Force Law</a></li><li><a href=/r/notes/griffiths/ch5-2/ class=navbutton>The Biot-Savart Law</a></li><li><a href=/r/notes/griffiths/ch5-3/ class=navbutton>The Divergence and Curl of B</a></li><li><a href=/r/notes/griffiths/ch5-4/ class=navbutton>Magnetic Vector Potential</a></li><li><a href=/r/notes/griffiths/ch6-1/ class=navbutton>Magnetization</a></li><li><a href=/r/notes/griffiths/ch6-2/ class=navbutton>The Field of a Magnetized Object</a></li><li><a href=/r/notes/griffiths/ch6-3/ class=navbutton>The Auxiliary Field H</a></li><li><a href=/r/notes/griffiths/ch6-4/ class=navbutton>Linear and Nonlinear Media</a></li><li><a href=/r/notes/griffiths/ch7-1/ class=navbutton>Electromotive Force</a></li><li><a href=/r/notes/griffiths/ch7-2/ class=navbutton>Electromagnetic Induction</a></li><li><a href=/r/notes/griffiths/ch7-3/ class=navbutton>Maxwell's Equations</a></li><li><a href=/r/notes/griffiths/ch8-0/ class=navbutton>Phys 544 Introduction</a></li><li><a href=/r/notes/griffiths/ch8-1/ class=navbutton>Charge and Energy</a></li><li><a href=/r/notes/griffiths/ch8-2/ class=navbutton>Momentum</a></li><li><a href=/r/notes/griffiths/ch9-1/ class=navbutton>Electromagnetic Waves in One Dimension</a></li><li><a href=/r/notes/griffiths/ch9-2/ class=navbutton>Wave Equation for E and B</a></li><li><a href=/r/notes/griffiths/ch9-3/ class=navbutton>Electromagnetic Waves in Matter</a></li><li><a href=/r/notes/griffiths/ch9-4/ class=navbutton>Electromagnetic Waves in Conductors</a></li><li><a href=/r/notes/griffiths/ch9-5/ class=navbutton>Guided Waves</a></li><li><a href=/r/notes/griffiths/ch10-1/ class=navbutton>Scalar and Vector Potentials</a></li><li><a href=/r/notes/griffiths/ch10-2/ class=navbutton>Retarded Potentials</a></li><li><a href=/r/notes/griffiths/ch10-3/ class=navbutton>Point Charges</a></li><li><a href=/r/notes/griffiths/ch11-1/ class=navbutton>Dipole Radiation</a></li><li><a href=/r/notes/griffiths/problems-ch3/ class=navbutton>Solved Problems Ch3</a></li><li><a href=/r/notes/griffiths/problems-ch5/ class=navbutton>Solved Problems Ch5</a></li><li><a href=/r/notes/griffiths/problems-ch7/ class=navbutton>Solved Problems Ch7</a></li><li><a href=/r/notes/griffiths/problems-ch9/ class=navbutton>Solved Problems Ch9</a></li></ul></li></ul></li></ul><ul class=book-menu-hugo><li><a href=https://github.com/Peppyhare/r target=_blank rel=noopener>Github</a></li><li><a href=https://themes.gohugo.io/hugo-book/ target=_blank rel=noopener>Hugo Themes</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/r/svg/menu.svg class=book-icon alt=Menu></label><h3>Mathematical review</h3><label for=toc-control><img src=/r/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#mathematical-review>Mathematical review</a><ul><li><a href=#fourier-series--spectral-analysis>Fourier Series / Spectral Analysis</a><ul><li><a href=#sturm-liouville-theory>Sturm-Liouville Theory</a></li></ul></li><li><a href=#series-with-finite-spectra>Series with finite spectra</a><ul><li><a href=#fourier-series-with-infinite-spectra>Fourier series with infinite spectra</a></li></ul></li><li><a href=#the-fourier-transform>The Fourier Transform</a></li><li><a href=#laplace-transform>Laplace Transform</a></li><li><a href=#important-fourier-transforms>Important Fourier Transforms</a><ul><li><a href=#unitary-fourier-transform>Unitary Fourier Transform</a></li><li><a href=#multi-dimensional-fourier-transforms>Multi-dimensional Fourier Transforms</a></li><li><a href=#space-time-fourier-transform>Space-time Fourier Transform</a></li></ul></li><li><a href=#putting-it-all-together>Putting it all together</a></li><li><a href=#dispersion-relation>Dispersion Relation</a><ul><li><a href=#phase-velocity>Phase velocity</a></li><li><a href=#group-velocity>Group velocity</a></li><li><a href=#growthdecay-of-modes-and-energy-as-a-complex-time-frequency>Growth/decay of modes and energy as a complex time frequency</a></li></ul></li><li><a href=#diffusion>Diffusion</a><ul><li><a href=#probability-distributions>Probability Distributions</a></li><li><a href=#statistical-moments>Statistical Moments</a></li><li><a href=#law-of-large-numbers>Law of Large Numbers</a></li><li><a href=#central--limit-theorem>Central Limit Theorem</a></li><li><a href=#random-walks-and-diffusion>Random Walks and Diffusion</a></li></ul></li><li><a href=#kinetic-theory>Kinetic Theory</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><link rel=stylesheet href=/r/katex/katex.min.css><script defer src=/r/katex/katex.min.js></script><script defer src=/r/katex/auto-render.min.js onload=loadKatex()></script><script>function loadKatex(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,trust:e=>["\\htmlId","\\href"].includes(e.command),macros:{"\\lcm":"\\mathop{\\mathrm{lcm}}","\\sen":"\\text{sen}\\,","\\dd":"\\mathop{\\mathrm{d} #1}","\\abs":"\\lvert #1 \\rvert","\\dd":"\\text{d}","\\cross":"\\times","\\pdv":"\\frac{\\partial #1}{\\partial #2}","\\curl":`\\nabla \\cross #1`,"\\vu":"\\mathbf{\\hat{#1}}","\\vdot":"\\dot","\\div":`\\nabla \\cdot #1`,"\\grad":`\\nabla`,"\\dv":"\\frac{d\\,#1}{d\\,#2}","\\gr":"\\gamma","\\vec":"\\mathbf{#1}","\\tagl":"\\tag{#1}","\\eqref":"(#1)","\\laplacian":`\\mathbf{\\nabla ^2}`,"\\label":"{}","\\negadelta":`\\nabla`,"\\eqref":"\\href{###1}{(\\text{#1})}","\\ref":"\\href{###1}{\\text{#1}}","\\label":"\\htmlId{#1}{}"}})}</script><span>\[\]</span><h1 id=mathematical-review>Mathematical review
<a class=anchor href=#mathematical-review>#</a></h1><p>We&rsquo;re starting off with some mathematical foundation to ensure we&rsquo;re all on the same page before we start talking about waves and collisions.</p><h2 id=fourier-series--spectral-analysis>Fourier Series / Spectral Analysis
<a class=anchor href=#fourier-series--spectral-analysis>#</a></h2><p align=center><img alt=fourier_series-011.png src=/r/img/556/fourier_series-011.png></p><p>First, let&rsquo;s not get confused between Fourier series and Fourier transforms. A Fourier series is the breakdown of a function defined on a finite interval into &ldquo;frequency components.&rdquo; For example, if we have \( f(x) : x \in [a, b] \), a Fourier series for \( f(x) \) pulls apart the <strong>discrete</strong> frequency components of the \( e^{ikx} \) modes that make up the function. Starting with a fundamental mode \( f_0 \), a first harmonic \( f_1 \), a second harmonic \( f_2 \), and so on and so forth. We won&rsquo;t end up with any energy in the frequencies between those modes, since it&rsquo;s a discrete series.</p><p>A Fourier transform is a transformation on a function on an infinite interval. When transformed, we end up with a continuous spectrum in frequency space. Same basic principles, but the important difference is a Fourier series is from a finite interval to a discrete spectrum.</p><p>There are also special geometries that don&rsquo;t follow the basic 1D Fourier transformation. For example, if a function is defined on a disk (polar coordinates), then the eigenfunctions of the transform are the Bessel functions, and we perform spectral analysis via a &ldquo;Bessel transform.&rdquo; In a spherical geometry we have spherical Bessel functions.</p><p>Fourier&rsquo;s important contribution was this: any arbitrarily capricious graph can be represented in the limit as a sum of sines and cosines. Fourier series are applicable in every area of physics. Why? Why are these trigonometric functions so applicable?</p><p>The complex exponentials \( e^{ikx} = \cos(kx) + i \sin(kx) \) are the eigenfunctions of 1D intervals. Every time we draw a graph on a continuous interval, these eigenfunctions are the &ldquo;best&rdquo; available basis for representing that graph on that interval. This makes more sense if we try to summarize Sturm-Liouville theory.</p><h3 id=sturm-liouville-theory>Sturm-Liouville Theory
<a class=anchor href=#sturm-liouville-theory>#</a></h3><p>Sturm-Liouville is a mature, complete theory of evolutionary equations. We&rsquo;ve talked about various types of evolution equations in basically every other section in these notes.</p><p>For example,</p><ul><li>Heat equation (diffusion): \( \pdv{u}{t} = D \pdv{^2u}{x} \)</li><li>Advection: \( \pdv{u}{t} + a \pdv{u}{x} = 0 \)</li><li>Advection-Diffusion (both): \( \pdv{u}{t} = \pdv{}{x}(D \pdv{u}{x}) + a \pdv{u}{x} \)</li></ul><p>Any generic evolution equation relates the time derivative to a differential operator</p><span>\[\pdv{u}{t} = A u\]</span><p>Sturm-Liouville is for all linear, 2nd-order operators \( A \). To make the notation a bit easier, let&rsquo;s use \( u_t \equiv \pdv{u}{t} \), \( u_{xx} \equiv \pdv{^2u}{x^2} \)</p><p>The standard form of a 2nd-order linear equation is</p><span>\[\begin{aligned}
u_t + f(t) u & = & a(x) u_{xx} + b(x) u_x + c(x) u \\
& = & A u
\end{aligned}\]</span><p>To solve the equation, we use separation of variables, where we say our solution will be a product of a function \( X(x) \) with all the spatial information and a function \( T(t) \) with all of the temporal information. When we substitute the solution, we find</p><span>\[(T' + f(x) T )X = T A X \\
\rightarrow \frac{AX}{X} = \frac{T' + f(t) T}{T}\]</span><p>Because the left-hand-side depends only on \( x \) and the right-hand-side depends only on \( t \), they must be equal to some constant \( \lambda \). We get two equations, the first being the eigenvalue problem</p><span>\[AX = \lambda X\]</span><p>and a temporal eigenvalue problem</p><span>\[T' = (\lambda - f(t) ) T\]</span><p>We start with the the spatial one, because in general we will know the spatial boundary conditions for our problem (otherwise it&rsquo;ll be rather difficult to solve!). For the 2nd order eigenvalue problem given sufficient boundary conditions for \( u \)</p><span>\[a(x) X'' + b(x) X' + (c(x) - \lambda) X = 0\]</span><p>we can get to the standard form with an integrating factor</p><p><span>\[I(x) = \frac{1}{a(x)} \exp \left( \int ^x \frac{b(y)}{a(y)} \\dy \right)\]
</span><span>\[\dv{}{x} \left( a(x) I \dv{X}{x} \right) + I(x) \left( c(x) - \lambda \right)X = 0\]</span></p><p>This is the standard Sturm-Liouville form. Or, on the internet we&rsquo;ll see the &ldquo;standard Sturm-Liouville form&rdquo; written slightly differently</p><span>\[\dv{}{x} \left( p(x) \dv{u}{x} \right) + q(x) u + \lambda w(x) u = 0\]</span><p>This form is important because of a miraculous theorem:</p><p><strong>Theorem</strong> Give regular boundary conditions on \( u(x) \) for \( x \in [a, b] \), the Sturm-Liouville equation has</p><ul><li>Distinct eigenvalues \( \lambda_n, n = 1, 2, \ldots \)</li><li>For each eigenvalue \( \lambda_n \) there is an eigenfunction \( X_n \).</li><li>The eigenfunctions form a complete set of orthogonal functions: \( \int _a ^b X_n X_m w(x) \dd x = 0, n \neq m \) (the weighting function \( w(x) \) is the above function in the standard S-L form). Completeness is the statement that one can expand any function on \( [a, b] \) using the set of eigenfunctions.</li><li>With the temporal eigenfunctions \( T_n(t) \), the solution to the S-L equation is the sum of all the eigenfunctions
<span>\[u(x, t) = \sum_{n=1} ^{\infty} a_n X_n(x) T_n (t)\]</span></li></ul><p>We start out with some temporal initial conditions</p><span>\[u_0 \equiv u(x, 0) = \sum_{n=1}^{\infty} a_n X_n(x)\]</span><p>We get the weighting coefficients \( a_n \) by taking the inner product of each eigenfunction with the initial conditions:</p><span>\[\langle X_m | u_0 \rangle = \sum_{n=1} ^{\infty} a_n \langle X_m | X_n \rangle \\
= a_m \langle X_m | X_m \rangle \\
\rightarrow a_m = \frac{\langle X_m | u_0 \rangle}{\langle X_m | X_m \rangle}\]</span><p>The completeness property of S-L gives families of orthogonal functions for any particular differential equation. The family we get ends up being a natural basis for physical situations.</p><p>Consider the Sturm-Liouville system:</p><ul><li>\( u^{\prime \prime} - \lambda ^2 u = 0 \) over the domain \( u \in [ -L / 2, L / 2] \)</li></ul><p>We&rsquo;ve got \( w(x) = 1 \) and inner product \( \langle X_n | X_m \rangle = \int _{-L/2} ^{L/2} X_n X_m \dd x \)</p><p>The eigenfunctions are \( \left[ \frac{1}{2}, \sin (\lambda _n x), \cos (\lambda_n x) \right] \) and the eigenvalues are \( \lambda_n = \frac{2 \pi}{L} n \)</p><p>The orthogonality relation says
<span>\[\langle u_n u_m \rangle = \int _{-L/2} ^{L} u_m (x) u_n (x) \dd x = 2 L \delta _{n m}\]</span></p><p>The Fourier basis is the <strong>simplest</strong> Sturm-Liouville system. It applies to systems that are on an interval and internally homogeneous.</p><p>There are other systems, like the Chebyshev, Hermite, and Laguerre polynomials. The only requirement is that the system satisfies a 2nd-order linear differential equation. But the Fourier basis satisfies the simplest possible 2nd-order S-L equation.</p><p>Back to Fourier series, let&rsquo;s get the Fourier theorem:</p><p><strong>Theorem</strong>: Any periodic function can be decomposed into a potentially infinite series of sine and cosine functions. If period is \( L \), that is (\( f(x + L) = f(x) \)), then</p><span>\[f(x) = \frac{a_0}{2} + \sum _{n=1} ^{\infty} a_n \cos (k_n x) + b_n \sin (k_n x)\]</span><p>with frequencies/wavenumbers given by</p><span>\[k_n = \frac{2 \pi}{L} n, n = 1, 2, 3, \ldots\]</span><p>and Fourier coefficients / expansion coefficients given by</p><p><span>\[a_n = \frac{2}{L} \int_0 ^L f(x) \cos (k_n x) \dd x\]
</span><span>\[b_n = \frac{2}{L} \int_0 ^L f(x) \sin (k_n x) \dd x\]</span></p><p>The set of coefficients \( a_n, b_n \) forms the spectrum of \( f(x) \). For the Fourier series to be convergent, the spectrum must decay sufficiently quickly, so we&rsquo;ll see the coefficients getting smaller as \( n \rightarrow \infty \).</p><p>We usually express the Fourier series using the more convenient complex form by making use of the Euler identity \( e^{i k x} = \cos (kx) + i \sin (kx) \)</p><p><span>\[f(x) = \sum_{n = -\infty} ^{\infty} c_n e^{i k_n x}\]
</span>In this form we only have a single set of coefficients given by the Fourier integral
<span>\[c_n = \frac{1}{L} \int_0 ^L f(x) e ^{-i k_n x} \dd x\]</span></p><p>You can show that they are related to the previous ones by</p><span>\[ c_n = \frac{1}{2} (a_n - i b_n) \qquad n > 0 \\
= \frac{1}{2} (a_n + i b_n) \qquad n &lt; 0>\]</span><p>Let&rsquo;s build some intuition by looking into some examples of Fourier spectra.</p><h2 id=series-with-finite-spectra>Series with finite spectra
<a class=anchor href=#series-with-finite-spectra>#</a></h2><blockquote class="book-hint info">**Simple Waveform**
<span>\[u = \sin (5x)\]
</span>By inspection,
<span>\[\sin (5x) = \frac{1}{2i} \left( e^{i 5x} - e ^{-i 5 x} \right)\]
</span>That was easy, that's the whole series. There are only two Fourier coefficients
<span>\[c_5 = - \frac{i}{2} \qquad c_{-5} = \frac{i}{2}\]</span></blockquote><blockquote class="book-hint info">**Beat wave**
<span>\[u = \cos (6x) \cos (x)\]
</span>Expanding each of the cosines as complex exponentials
<span>\[u = \frac{1}{4} \left( e^{i 6 x} + e^{- i 6 x} \right) (e^{ix} + e^{-ix})\]
</span><span>\[= \frac{1}{4} \left( e^{i 7 x} + e^{-i 7 x} + e^{i 5 x} + e^{-i 5 x} \right)\]
</span><span>\[= \frac{1}{2} \left( \cos (7x) + \cos (5x) \right)\]
</span>So we've got four coefficients
<span>\[c_{\pm 5} = \frac{1}{4}, \qquad c_{\pm 7} = \frac{1}{4}\]</span></blockquote><h3 id=fourier-series-with-infinite-spectra>Fourier series with infinite spectra
<a class=anchor href=#fourier-series-with-infinite-spectra>#</a></h3><blockquote class="book-hint info">**Square Wave**
<span>\[f(x) = \begin{cases} 1 & \qquad & 0 &lt; x &lt; T/2 \\
-1 & \qquad & -T/2 &lt; x &lt; 0
\end{cases}\]
</span>This is about as discontinuous as you get. If you do the Fourier integrals, you get
<span>\[f(x) = \sum_{n = \text{odd}} \frac{-i}{\pi n} e^{i k_n x}\]
</span><span>\[|c_n| \sim \frac{1}{n}\]
</span>The series has a slow convergence, and if you plot the spectrum you get a power law relationship.</blockquote><blockquote class="book-hint info">**Triangle Wave**
The points of the triangle wave where the function is continuous but not differentiable give us a similarly slow convergence of the Fourier spectrum. For a triangle wave it ends up that
<span>\[| c_n| \sim \frac{1}{n^2}\]
</span>so they converge an order faster than a square wave, but still very slowly.</blockquote><blockquote class="book-hint info">**Elliptic Cosine**
Sort of like a cosine, except that it's defined on an ellipse instead of a circle. We give it some parameter \\( m \\) that relates to the ellipticity
<span>\[f(x) = c_n (x | m)\]
</span>It's periodic, continuous, and infinitely differentiable _but_ its Fourier coefficients behave like
<span>\[|c_n | \sim \text{sech}(b_n (1 + 2n)) \sim e^{-n}\]
</span>so the spectrum converges _fast_.</blockquote><p>To summarize, functions with discontinuities and non-differentiable points had Fourier coefficients that decay with a power law. Continuous, differentiable functions converge very fast. A general conclusion is that non-differentiable functions (or functions that are non-smooth at some level) have infinite power law spectra.</p><h2 id=the-fourier-transform>The Fourier Transform
<a class=anchor href=#the-fourier-transform>#</a></h2><p>The Fourier transform is a two-sided representation of a function defined everywhere on the real line \( f \in (- \infty, \infty) \). As we calculate the Fourier series for the bounded interval and take the limit of the bounded interval out to the real line, we obtain the Fourier transform.</p><p>Basically every function has a Fourier transform. As we extend to \( \infty \), we have a very different set of boundary conditions than before. For the Fourier transform to exist, the function must decay sufficiently rapidly for the Fourier integral to converge. If we admit generalized functions or delta functions (as we should!), even functions that don&rsquo;t decay have transforms.</p><p>First, we start with our Fourier series</p><span>\[f(x) = \sum_{n = - \infty} ^{\infty} c_n e^{i k _n x} \qquad k_n = \frac{2 \pi}{L} n \qquad c_n = \frac{1}{L} \int_0 ^{L} f(n) e^{- i k_n x} \dd x\]</span><p>we extend the limits of integration out from \( [0, L] \) to \( (-\infty, \infty) \). The previously discrete spectrum becomes continuous as the distance between successive \( k_n \) goes to 0</p><span>\[k_n = \frac{2 \pi}{L} n \qquad \Delta k_n = \frac{2 \pi}{L} \rightarrow 0\]</span><p>Taking the limit, we get the Fourier transform pair</p><p><span>\[f(x) = \int _{-\infty} ^{\infty} e^{i k x} \dd k\]
</span><span>\[\hat {f} (x) = \frac{1}{2 \pi} \int _{-\infty} ^{\infty} f(x) e^{- i k x} \dd x\]</span></p><p>Fourier transforms are appropriate to analyze a linear, homogeneous medium, e.g. system where the same linear differential equation is satisfied everywhere in space.</p><h2 id=laplace-transform>Laplace Transform
<a class=anchor href=#laplace-transform>#</a></h2><p>Also known as a one-sided Fourier transform, or a generalized Fourier transform.</p><p>Consists of a transform over just half of the infinite interval: \( [0, \infty] \). This makes it appropriate for time problems / initial value problems where we need to treat the time variable.</p><p>The time spectrum of \( f(t) \) is
<span>\[\hat {f}(\omega) = \int _0 ^\infty f(t) e^{i \omega t} \dd t\]</span></p><p>In general, we use the convention \( \mathcal{L}(f(t)) = F(s) \) to denote the Laplace transform of \( f(t) \), with an opposite sign convention for \( s \) vs \( i \omega \) (\( s = - i \omega \)):</p><span>\[F(s) = \int _{0} ^{\infty} e^{-s t} f(t) \dd t\]</span><p>with inverse transform
<span>\[f(t) = \frac{1}{2 \pi} \int _{-\infty + i s} ^{\infty + i s} f(\omega) e ^{- i \omega t} \dd \omega\]
</span>or
<span>\[f(t) = \mathcal{L}^{-1}[F(s)] = \frac{1}{2 \pi i} \int _{-\infty +is} ^{\infty + is} e^{st} F(s) \dd s \]</span></p><p>Because \( s \) is complex-valued, the inverse Laplace integral is an integral over the complex plane. The factor \( i s \) is there in order for the transform pair to be convergent. Contour \( i s \) has to be above all of the poles of \( f(\omega) \). In practice, we compute the complex integral using the Cauchy integral theorem, which says that for any simple closed curve \( C \) in the complex plane, then for any \( z_0 \) inside \( C \):</p><span>\[\oint _C \frac{f(z)}{z - z_0} \dd z = 2 \pi i f(z_0)\]</span><p>if \( f(z) \) is an analytic function (without poles) everywhere inside the closed contour \( C \) (which is traversed in the counterclockwise direction). Since the path integral of an analytic function is independent of the path, we may deform paths to suit ourselves unless they encounter a pole, in which case the Cauchy integral theorem tells us that the contribution from circumnavigating the pole is given by the <em>residue</em> of the poles:</p><span>\[\oint _C F(z) \dd z = 2 \pi i \sum_k \text{res} _k\]</span><p>where the residue of a simple pole (a pole with the form \( 1/(z - z_k) \)) is
<span>\[\text{res}_k = \lim _{z \rightarrow z_k} (z - z_k) F(z)\]</span></p><p>In general, if \( g(z) \) is a polynomial function with roots \( z_j \) of degree \( D_j \), the <strong>residue</strong> of a function \( f(z)/g(z) \) at root \( z_j \) of \( g \) is:</p><span>\[\text{res}(z_j) = \lim_{z \rightarrow z_j} \frac{1}{(D_j - 1)!} \frac{\dd ^{D_j - 1}}{\dd z^{D_j - 1}} (z - z_j)^{D_j} \frac{f(z)}{g(z)}\]</span><div class=book-tabs><input type=radio class=toggle name=tabs-38 id=tabs-38-0 checked>
<label for=tabs-38-0>Q</label><div class="book-tabs-content markdown-inner">**Example: Inverse Laplace Transform with Cauchy Residue**
For example, compute the inverse Laplace transform of
<span>\[F(s) = \frac{1}{(s + 1)^2}\]
</span>using the Cauchy residue formula</div><input type=radio class=toggle name=tabs-38 id=tabs-38-1>
<label for=tabs-38-1>A</label><div class="book-tabs-content markdown-inner"><span>\[\mathcal{L}^{-1}[F(s)] = \frac{1}{2 \pi i} \int _{-\infty} ^{\infty} F(s) e^{st} \dd s \\
= \frac{1}{2 \pi i} \left[ 2 \pi i \sum_k \text{res}_k \left( F(s) e^{st} \right) \right]\]
</span>In this case, \\( F(s) \\) has a single pole of degree 2 at \\( s = -1 \\). The residue of \\( F(s) e^{st} \\) at \\( s = -1 \\) is
<span>\[\text{res}(-1) = \lim_{s \rightarrow -1} \frac{1}{(1)!} \dv{}{s} \left[(s + 1)^2 \frac{e^{st}}{(s+1)^2} \right] \\
= \lim_{s \rightarrow -1} t e^{st} \\
= t e^{-t}\]</span></div></div><h2 id=important-fourier-transforms>Important Fourier Transforms
<a class=anchor href=#important-fourier-transforms>#</a></h2><p>Representative of the most important features of the Fourier Transform:</p><blockquote class="book-hint info">**Gaussian**
<span>\[f(x) = e^{- \alpha x ^2} \qquad \hat {f} (k) = \frac{1}{\sqrt{2 \alpha}} e ^{- k ^2 / 4 \alpha}\]
</span>Note that if \\( \alpha = 1/2 \\), it is its own transform pair. The Gaussian is one of the only eigenfunctions of the Fourier transform.</blockquote><blockquote class="book-hint info">**Derivative**
<span>\[\pdv{^nf}{x^n} \quad \leftrightarrow \quad (i k) ^n \hat{f}(k)\]
</span>In this way, linear differential equations become simple algebraic equations in their Fourier transformed form.</blockquote><blockquote class="book-hint info">**Wave**
The Fourier transform of a single wave component is the Dirac delta function
<span>\[f(x) = e^{i k_0 x} \qquad \hat{f}(k) = \sqrt{2 \pi} \delta (k - k_0)\]</span></blockquote><h3 id=unitary-fourier-transform>Unitary Fourier Transform
<a class=anchor href=#unitary-fourier-transform>#</a></h3><p>The factor of \( 1/ 2\pi \) in front of either the Fourier transform or its inverse can be moved to either side by convention. The &ldquo;unitary&rdquo; Fourier transform convention splits it evenly across both:</p><p><span>\[f(x) = \frac{1}{\sqrt{2 \pi}} \int _{- \infty} ^{\infty} \hat{f} (k) e^{i k x} \dd x\]
</span><span>\[\hat{f}(k) = \frac{1}{\sqrt{ 2 \pi}} \int _{- \infty} ^{\infty} f(x) e^{- i k x} \dd x\]</span></p><p>We&rsquo;ll use this notation going forward.</p><h3 id=multi-dimensional-fourier-transforms>Multi-dimensional Fourier Transforms
<a class=anchor href=#multi-dimensional-fourier-transforms>#</a></h3><p>Extending to more dimensions, we can do multi-dimensional Fourier transforms by transforming each coordinate successively.</p><span>\[f(x, y) \rightarrow \hat{f}(k, l) = \frac{1}{2 \pi} \int _{- \infty} ^{\infty} \dd x \int _{- \infty} ^{\infty} \dd y \, e^{- i (k x + ly)} f(x, y)\]</span><p>Let vectors \( \vec k = (k, l) \), \( \vec x = (x, y) \), then the phase factor \( k x + l y = \vec k \cdot \vec x \).</p><p>An N-dimensional transform is just</p><span>\[\hat{f}(\vec k) = \frac{1}{(2 \pi)^{d/2}} \int _{- \infty} ^{\infty} \dd ^d x \, e^{-i \vec k \cdot \vec x} f(\vec x)\]</span><p>If you do it in cylindrical coordinates, you end up with a Bessel function as your transform.</p><h3 id=space-time-fourier-transform>Space-time Fourier Transform
<a class=anchor href=#space-time-fourier-transform>#</a></h3><p>The space-time Fourier Transform is also useful, where we combine both the time and space transforms to deal with differential equations that are functions of both space and time. We pretend time extends in both directions for this; otherwise we would have the initial conditions we&rsquo;d use for a Laplace transform and we would have an easier situation on our hands.</p><span>\[f(\vec x, t) \rightarrow \hat{f}(\vec k) = \frac{1}{4 \pi ^2} \int _{- \infty} ^{\infty} \dd ^3 x \, e^{- i \vec k \cdot \vec x} \int _{- \infty} ^{\infty} \dd t \, e^{ i \omega t} f(\vec x, t)\]</span><p>Note the flipped &ldquo;signature&rdquo; of the time transform, where the phase of the complex exponential has an opposite sign. Time has an opposite &ldquo;direction&rdquo; to space, and this convention ends up being the most meaningful.</p><p>The inverse transform just integrates the other way around with the signs flipped.</p><span>\[f(\vec x, t) = \int _{- \infty} ^{\infty} \dd ^3 k \int _{- \infty} ^{\infty} \dd \omega \hat f (\vec k, \omega) e^{i (\vec k \cdot \vec x - \omega t)}\]</span><p>Looking at the two components of the transform, \( \hat f (\vec k, \omega) \) in a sense represents the equivalent of the Fourier coefficients / amplitudes. \( e^{i (\vec k \cdot \vec x - \omega t)} \) is a waveform with wave vector \( \vec k \) and frequency \( \omega \)</p><p>Important properties of the space-time Fourier transform are:</p><ul><li>The spatial part satisfies:<ul><li>\( \dv {^n f}{x^n} \rightarrow (i k) ^n \hat f \)</li><li>\( \grad f \rightarrow i \vec k \hat f \)</li><li>\( \div f \rightarrow i \vec k \cdot \hat f \)</li><li>\( \curl f \rightarrow i \vec k \cross \hat f \)</li><li>\( \grad ^2 f \rightarrow (i k)^2 \hat f \rightarrow - k^2 \hat f \)</li></ul></li></ul><p>So there is a symbolic correspondence between \( \grad \) and \( i \vec k \)</p><ul><li>The time part satisfies<ul><li>\( \pdv {^n f}{t^n} \rightarrow (- i \omega)^n \hat f\)</li></ul></li></ul><p>Writing out all of the correspondences,</p><table><thead><tr><th>Space-time domain</th><th>Fourier domain</th></tr></thead><tbody><tr><td>\( (\vec x, t) \)</td><td>\( (\vec k, \omega) \)</td></tr><tr><td>\( \grad \)</td><td>\( i \vec k \)</td></tr><tr><td>\( \pdv{}{t} \)</td><td>\( -i \omega \)</td></tr></tbody></table><p>PDE&rsquo;s in space and time become algebraic equations that can be much more easily solved in the Fourier domain.</p><h2 id=putting-it-all-together>Putting it all together
<a class=anchor href=#putting-it-all-together>#</a></h2><p>To summarize, we solve linear differential equations on the finite interval of the form</p><p><span>\[u_t = A u \rightarrow u(x, t) = X(x)T(t)\]
</span>by a separation of variables, and the choice of a basis set of eigenfunctions for the spatial solution.
<span>\[\rightarrow AX = \lambda X \rightarrow (\lambda _n, x_n)\]
</span><span>\[T' = \lambda T \rightarrow T_n = e^{\lambda _n t}\]
</span><span>\[u(x, t) = \sum_{n = -\infty} ^{\infty} C_n X_n(x) T_n (t)\]
</span><span>\[u_0 \equiv u(x, 0) = \sum_{n = -\infty} ^{\infty} C_n X_n (x)\]
</span><span>\[\langle u_0 | X_m \rangle = \sum_n C_n \langle X_n | X_m \rangle\]
</span><span>\[\langle X_n | X_n \rangle = 1 \quad \text{(normalized eigenfunctions)}\]
</span><span>\[C_n = \frac{\langle u_0 | X_m \rangle}{\langle X_n | X_n \rangle}\]</span></p><p>So the coefficients are projections of the initial condition onto the basis.</p><ul><li>The eigenfunctions evolve independently</li><li>The evolution of the full solution is the sum of the evolutions of each of the modes</li><li>The spectral coefficients are the projection of the initial conditions onto the basis.</li></ul><p>Fourier modes arise naturally. Take for example the advection equation</p><p><span>\[\pdv{u}{t} + c \pdv {u}{x} = 0 \qquad x \in [0, L]\]
</span><span>\[u_0 \equiv u(x, t = 0) \quad \text{(given initial condition)}\]
</span><span>\[u(x+ L, t) = u(x, t) \quad \text{(periodic boundary conditions)}\]
</span>Look for separable solutions \( u = X(x) T(t) \)
<span>\[X T' + c X' T = 0\]
</span><span>\[\frac{X'}{X} = -\frac{1}{c} \frac{T'}{T} = \lambda\]
</span><span>\[\rightarrow X' = \lambda X \qquad \rightarrow X = A e^{\lambda x}\]
</span>Applying periodic boundary condition,
<span>\[X(x + L) = X(x) \rightarrow A e^{\lambda x} e^{\lambda L} = A e^{\lambda x}\]
</span><span>\[e^{\lambda L = 1} \rightarrow \lambda_n = \frac{2 \pi}{L} i n, \quad n = ... -3, -2, -1, 0, 1, 2, 3, ...\]
</span><span>\[k_n \equiv \frac{2 \pi}{L} n\]
</span><span>\[X(x) = e^{i k_n x}\]
</span>The spatial eigenfunctions fall out as the Fourier basis.
<span>\[T_n ' = - c T_n \lambda _n \rightarrow T_n = - i c k_n T_n\]
</span><span>\[\rightarrow T_n = B e^{- i c k_n t}\]
</span><span>\[u(x, t) = \sum_{n = - \infty} ^{\infty} c_n e^{i k_n (x - ct)}\]
</span>The initial condition can just be written as a Fourier series, since the time component at \( t= 0 \) is just \( 1 \)
<span>\[u_0 = \sum_{n = - \infty} ^{\infty} c_n e ^{i k _n x}\]
</span><span>\[\langle u_0 | e^{i k _m x} \rangle = \sum_n c_n \langle e ^{i k _n x } | e^{i k_n x} \rangle\]
</span><span>\[\langle e^{i k_n x} | e^{i k _m x} \rangle = \int _0 ^L e^{i k _n x} e^{i k_m x} \dd x\]
</span><span>\[= \int _0 ^L e^{i x(2 \pi / L)(n + m)} \dd x\]
</span><span>\[= \frac{1}{(2 \pi / L) i (n + m)} \left. e^{i (2 \pi / L) x (n + m)} \right|_0 ^L\]
</span>The argument is 0 unless \( n = -m \), so
<span>\[= L \delta _{n - m}\]
</span><span>\[c_n = \frac{1}{L} \int _0 ^L u_0 (x) e^{- i k_n x} \dd x\]
</span>which is exactly the Fourier integral of the initial condition.</p><p><span>\[\pdv{u}{t} + c \pdv{u}{x} = 0\]
</span><span>\[\rightarrow u (x, t) = \sum_{n = - \infty} ^{\infty} c_n e^{i (k_n x - k_n c t)}\]</span></p><p>Recall the symbolic correspondence \( (\vec k, \omega) \leftrightarrow (\vec x, t) \), \( i \vec k \leftrightarrow \grad \), and \( - i \omega \leftrightarrow \pdv{}{t} \). Applying these to the advection equation,</p><p><span>\[\partial _t u + c \partial _x u = 0 \leftrightarrow - i \omega \hat u + i k c \hat u = 0\]
</span><span>\[\hat u (-i)(\omega - c k) = 0\]
</span>We want non-trivial solutions, so \( \hat u \neq 0 \), so we obtain a relationship between the time frequency and the wavenumber called the dispersion relation
<span>\[\omega = c k\]</span></p><p>The wavenumbers in \( [0, L] \) are \( k_n = \frac{2 \pi}{L} n \)
<span>\[u(x, t) = \sum_{n = - \infty} ^{\infty} a_n e^{i (k_n x - \omega (k_n) t)}\]
</span>which is our general solution for all linear problems on the interval. It depends only on the wavenumbers \( k_n \) and the interval \( L \). In this case we see it really only depends on what the dispersion relation was.</p><p>In cases where the interval becomes very large, the solution consists of an integral over all wavenumbers
<span>\[L \rightarrow \infty\]
</span><span>\[u(x, t) = \int _{-\infty} ^{\infty} A(k) e^{i k x - \omega(k) t} \dd k\]
</span>where \( A(k) \) are the spectral coefficients of the initial condition (not the linear operator). This is the general solution to linear evolution equations.</p><h2 id=dispersion-relation>Dispersion Relation
<a class=anchor href=#dispersion-relation>#</a></h2><p>The <strong>dispersion relation</strong> \( \omega = \omega(k) \) is a functional relation between the time and space frequencies and is a consequence of the physical situation. You can think of it as a signature consequence of the PDE or system of equations in question.</p><p>Any homogeneous partial differential equation may be written in the form \( A (\grad, \pdv{}{t}) \cdot \vec u = 0 \) for a differential operator \( A(\grad, \pdv{}{t}) \). This is symbolically equivalent to a dispersion function \( D(\omega, k) \cdot \hat u = 0 \). Because the PDE describes the motion of \( u \), the solutions of the dispersion function also describe the motion.</p><h3 id=phase-velocity>Phase velocity
<a class=anchor href=#phase-velocity>#</a></h3><p>Consider a single phase component or a single wave</p><span>\[e^{i (\vec k \cdot \vec x - \omega t)}\]</span><p>In 1-D, factor out the \( k \): \( k (x - \frac{\omega}{k} t) \). Along the line \( x = \frac{\omega}{k}t \), the phase is constant. The apparent velocity of a single phase component is
<span>\[v_\phi = \frac{\omega}{k}\]</span></p><h3 id=group-velocity>Group velocity
<a class=anchor href=#group-velocity>#</a></h3><p>This is a bit more complicated, and first we&rsquo;ll need the concept of the principle of stationary phase.</p><p><span>\[u(x, t) = \int _{-\infty} ^{\infty} A(k) e^{i (kx - \omega t)} \dd x\]
</span>The arbitrary solution arises from coalescing waves in just the right phases. If we start with some sort of shape and want to know how it moves, we need to consider that it is composed of many waves that may have phases moving in totally different directions, but if a bunch of waves move in phase with each other then we&rsquo;ll see an apparent motion of the shape.</p><p>First we look at the total phase function
<span>\[\phi = k x - \omega t\]
</span>and Taylor expand the phase function around a stationary wave mode \( k_0 \)
<span>\[\phi = \phi(k_0) + \left. \pdv{\phi}{k} \right| _{k = 0} (k - k_0) + \frac{1}{2} \left. \pdv{^2 \phi}{k^2} \right| _{k = k_0} (k - k_0 )^2 + \ldots\]
</span><span>\[\phi _k = k - \pdv{\omega}{k} t\]
</span><span>\[\phi_{kk} = - \omega_{kk} \cdot t\]
</span><span>\[\rightarrow \phi = \phi(k_0) + \left( x - \left.\pdv{\omega}{k}\right|_{k_0} \cdot t \right)(k - k_0) - \frac{1}{2} \left.\omega_{kk}\right|_{k_0} (k - k_0) ^2 \]</span></p><p>The Riemann-Lebesgue Lemma is helpful here: Consider this integral
<span>\[\int _{-\infty} ^{\infty} f(k) e^{-i k t} \dd x\]
</span>and consider the limit as \( t \rightarrow \infty \). This is like asking what are the Fourier coefficients of the very highest modes? What is the behavior at the very largest wavenumbers? For the integral to converge, the highest wavenumber needs to go to zero. The Riemann-Lebesgue lemma says that the limit of the integral is zero even for functions like trigonometric curves. The idea is that Fourier modes of infinite wavenumber have zero energy, otherwise the integral that defines it won&rsquo;t converge.</p><p>Consider the solution
<span>\[u(x, t) = \int _{-\infty} ^{\infty} A(k) e^{i \phi(k)} \dd k\]
</span>and look at the Taylor expansion
<span>\[\phi(k) = \phi(k_0) + (x - \omega_k t) (k - k_0) - \frac{1}{2} \omega_{kk} t (k - k_0) ^2 + \ldots\]
</span>Because of the Riemann-Lebesgue lemma, any terms that are first-order (linear) in \( k \) will vanish in the limit \( t \rightarrow \infty \). Everywhere with a non-zero linear term will go to zero. The physical intuition of the Riemann-Lebesgue lemma is that the function goes to zero at infinity as a result of destructive interference.</p><p>Where does the linear term vanish? when
<span>\[x - \left. \pdv{\omega}{k} \right|_{k_0} t = 0\]
</span>This defines a set of coordinates \( x = \pdv{\omega}{k} \cdot t \). Along this trajectory, the asymptotic behavior of the integral does not vanish. Breaking the integral into three components, two limits and one region where the Taylor expansion is valid:
<span>\[\lim _{t \rightarrow \infty} u = \lim_{t \rightarrow \infty} \int _{-\infty} ^{k_0 - \delta k} (I) + \int _{k_0 - \delta k} ^{k_0 + \delta k} (I) + \int_{k_0 + \delta k} ^{\infty}\]</span></p><p>The outside components will be zero, because there</p><p><span>\[x - \left. \pdv{\omega}{k} \right|_{k_0} t = 0\]
</span>is not satisfied, but inside the window we obtain the asymptotic behavior of our waveform
<span>\[\lim_{t \rightarrow \infty} u(x, t) = \int_{k_0 - \delta k} ^{k_0 + \delta k} A(k) e^{i \phi(k)} \dd k\]</span></p><p>Now, suppose the dispersion relation is only quadratic, so we only keep terms up to \( \omega_{kk} \neq 0 \), \( \omega_{kkk} = 0 \).
<span>\[u(x, t) = A(k_0) e^{i \phi (k_0)} \int_{k_0 - \delta k} ^{k_0 + \delta k} e^{- i \frac{1}{2} \omega_{kk} (k - k_0 )^2 t} \dd x\]
</span>If we actually carry out the integral,
<span>\[\lim_{t \rightarrow \infty} u = A(k_0) \sqrt{\frac{\pi}{2 \omega_{kk} |_{k_0} t}} e^{i (k_0 x - \omega_0 t + \pi / 4)}\]</span></p><p>This is called the stationary phase solution for the asymptotic behavior of the solution. Looking at the solution, the wave &ldquo;spreads out&rdquo; due to the quadratic part of \( \omega \). The amplitude shrinks at the rate \( 1/\sqrt{2 \omega_{kk} t} \) \sim t^{-1/2}. That&rsquo;s why it&rsquo;s called dispersion. At the same time as the amplitude shrinks, the wave is moving on the trajectory that satisfies
<span>\[x - \left. \pdv{\omega}{k} \right|_{k_0} t = 0 \rightarrow x = \left. \pdv{\omega}{k} \right|_{k = k_0} \cdot t\]
</span>This velocity is called the <strong>group velocity</strong>, because it describes the motion of structures that are not composed of a single wave / phase component.
<span>\[\left. \pdv{\omega}{k} \right|_{k = k_0} \quad \text{Group velocity}\]</span></p><p>For linear dispersion relations, the group velocity and the phase velocity are the same, but for more complicated functions they are not.</p><h3 id=growthdecay-of-modes-and-energy-as-a-complex-time-frequency>Growth/decay of modes and energy as a complex time frequency
<a class=anchor href=#growthdecay-of-modes-and-energy-as-a-complex-time-frequency>#</a></h3><p>Because \( \omega \) comes from the roots of some arbitrary dispersion function \( D(\omega, k) = 0 \), we know that \( \omega \) will be complex valued. We can split the frequency into its real and imaginary parts
<span>\[\omega(k) = \omega_r(k) + i \omega_i (k)\]
</span><span>\[e^{i (kx - \omega t)} = e^{\omega_i t} e^{i (kx - \omega_r t)}\]
</span>The imaginary component gives a regular exponential function. The real component in the complex exponential describes bounded waves. So the amplitude is described by the imaginary part \( \omega_i \).</p><p>If we&rsquo;re summing up over all those modes
<span>\[\int A(k) e^{\omega_i t} e^{i (kx - \omega_r t)} \dd x\]
</span>the amplitudes include the exponential \( e^{\omega_i t} \).</p><ul><li>If \( \omega_i > 0 \), modes grow exponentially in time</li><li>If \( \omega_i &lt; 0 \), modes shrink or damp with t</li></ul><h2 id=diffusion>Diffusion
<a class=anchor href=#diffusion>#</a></h2><h3 id=probability-distributions>Probability Distributions
<a class=anchor href=#probability-distributions>#</a></h3><blockquote><p>Check out Probability Theory (Jaynes) for a much more detailed reference.</p></blockquote><p>Some variables are random, in some sense. They may take on a set of values with different probability. If \( X \) is a random variable, the set of probabilities assigned to each possible outcome of \( X \) is called its probability distribution.</p><h4 id=discrete-distributions>Discrete distributions
<a class=anchor href=#discrete-distributions>#</a></h4><p>In a discrete distribution, \( X \) can take on finitely/countably many values.</p><p>Everyone loves the good old Binomial distribution: Suppose we conduct \( n \) independent experiments with a binary outcome of success or failure. Let the probability of success \( P(S) = p \), so the probability of failure \( P(F) = 1 - p \). How likely is it to have \( k \) successes in \( n \) trials?</p><p><span>\[P(S^k) = \begin{pmatrix} n \\ k \end{pmatrix} p^k (1 - p) ^{n-k}\]
</span>where
<span>\[\begin{pmatrix} n \\ k \end{pmatrix} \equiv \frac{ n!}{k! (n-k)!}\]</span></p><h4 id=continuous-distributions>Continuous distributions
<a class=anchor href=#continuous-distributions>#</a></h4><p>In a continuous distribution \( X \) can take on a continuous range of values.</p><p>When the random variable can take on a continuum of possible values (e.g. particle velocity), the distribution is a continuous function. Just integrate to get the probability that the value is within a range.</p><span>\[P(X = x) = f(x)\]</span><h3 id=statistical-moments>Statistical Moments
<a class=anchor href=#statistical-moments>#</a></h3><p>We can define moments of the probability distribution, which are going to be <em>very</em> important in kinetic theory and in probability theory (and in general).</p><blockquote class="book-hint info">**0th moment: Normalization**
Probability density functions are required to be normalized to 1. In the discrete case, this amounts to
<span>\[\sum _{i} P(X = x_i) = 1\]
</span>In the continuous case,
<span>\[\int _{\Omega} f(x) \dd x = 1\]</span></blockquote><blockquote class="book-hint info">**1st moment: Expected value or weighted average**
<span>\[\mathbf{E}[X] \equiv \sum_i x_i p_i\]
</span><span>\[\langle X \rangle = \sum_{\Omega} x f(x) \dd x\]</span></blockquote><blockquote class="book-hint info">**2nd moment: "Variance" (square of the standard deviation)**
Describes the spread in the outcomes
<span>\[\mathbf{V}(X) = \sum_i x_i ^2 p_i\]
</span><span>\[\langle X^2 \rangle = \int x^2 f(x) \dd x\]</span></blockquote><blockquote class="book-hint info">**General Nth moment:**
<span>\[\langle X^n \rangle = \int x^n f(x) \dd x\]</span></blockquote><h3 id=law-of-large-numbers>Law of Large Numbers
<a class=anchor href=#law-of-large-numbers>#</a></h3><p>Pretty straightforward, independent measurements of random variables work as you would expect.</p><blockquote><p>If a random variable is repeatedly sampled \( n \) times, then in the limit of \( n \rightarrow \infty \), the average value of those samples will converge to the expected value.</p></blockquote><h3 id=central--limit-theorem>Central Limit Theorem
<a class=anchor href=#central--limit-theorem>#</a></h3><p>Many distributions result from summing independent and identical random variables. In the binomial distribution above, each trial is an independent random variable.</p><blockquote><p>When a distribution results from summing \( n \) independent and identical random variables, in the limit \( n \rightarrow \infty \) the distribution will approach a normal distribution.</p></blockquote><p>For the binomial distribution (deMoivre-Laplace theorem),</p><span>\[\lim _{n \rightarrow \infty} \begin{pmatrix}n \\ k \end{pmatrix} p^k (1 - p) ^{n - k} \rightarrow \frac{1}{\sqrt{2 \pi n p (1 - p)}} e^{- \frac{1}{2} \frac{(k - np)^2}{2 n p (1- p)}}\]</span><p>A normal distribution is a distribution that has the form</p><span>\[f(x) = \frac{1}{\sqrt{2 \pi} \sigma} e^{ - \frac{1}{2} \left( \frac{x - \mu}{\sigma} \right)^2}\]</span><p><span>\[\langle X \rangle = \mu \quad \text{(Average value)}\]
</span><span>\[\langle X^2 \rangle = \sigma^2 \quad \text{(Standard deviation)}\]</span></p><p>This property of the normal distribution alone would account for it showing up in so many areas of physics, but it has another remarkable property: If we define a quantity called &ldquo;entropy&rdquo; as
<span>\[S = - \int f(x) \ln (f) \dd x\]</span></p><p>that measures the information/complexity of the distribution, then <strong>the normal distribution has the maximum entropy among all distributions with the same mean and variance.</strong></p><h3 id=random-walks-and-diffusion>Random Walks and Diffusion
<a class=anchor href=#random-walks-and-diffusion>#</a></h3><p>If we track the position of a one-dimensional random walker that has an equal chance to move a distance \( \Delta x = h \) to the left or right each step, and takes a step each interval \( \Delta t = \tau \). Let \( k \) be the number of steps to the right.</p><p><span>\[x = (k - (n - k))h = (2k - n)h \equiv m h\]
</span><span>\[k = \frac{n + m}{2}\]</span></p><p>The probability that we took \( k \) steps to the right after \( n \) steps is given by the binomial distribution with \( p = 1/2 \)</p><span>\[f_n (k) = \begin{pmatrix}n \\ k \end{pmatrix} \frac{1}{2^n}\]</span><p>The construction of Pascal&rsquo;s triangle comes from the recursion relation, adding the previous rows
<span>\[\begin{pmatrix} n \\ k \end{pmatrix} = \begin{pmatrix} n - 1 \\ k \end{pmatrix} + \begin{pmatrix} n - 1\\ k - 1 \end{pmatrix}\]
</span>\( n \rightarrow n + 1 \)
<span>\[\begin{pmatrix} n+ 1 \\ k \end{pmatrix} = \begin{pmatrix} n \\ k \end{pmatrix} + \begin{pmatrix} n \\ k - 1\end{pmatrix}\]
</span>\( k \rightarrow k + 1/2 \)
<span>\[\begin{pmatrix} n + 1 \\ k + 1/2 \end{pmatrix} = \begin{pmatrix} n \\ k + 1/2 \end{pmatrix} + \begin{pmatrix} n \\ k- 1/2 \end{pmatrix}\]
</span>\( k = \frac{n + m}{2} \)
<span>\[\begin{pmatrix} n + 1\\ \frac{n + 1 + m}{2} \end{pmatrix} = \begin{pmatrix} n \\ \frac{n + (m + 1)}{2} \end{pmatrix} + \begin{pmatrix} n \\ \frac{n + (m - 1)}{2} \end{pmatrix}\]</span></p><p>From that, we can conclude that
<span>\[f_n (k / m) = \begin{pmatrix} n \\ k \end{pmatrix} \frac{1}{2^n} = \begin{pmatrix} n \\ \frac{n + m}{2} \end{pmatrix} \frac{1}{2^n}\]
</span><span>\[f_{n+1} (m) = \frac{1}{2} \left( f_n (m+1) + f_n (m-1) \right)\]
</span>In words, the probability of reaching position \( x \) after \( n \) steps is the average of the probabilities of reaching position \( x - h \) after \( n-1 \) steps and reaching position \( x + h \) after \( n - 1 \) steps.</p><span>\[f_{n+1} (m) - f_n (m) = \frac{1}{2} (f_n (m+1) - 2 f_n (m) + f_n (m-1))\]</span><p>This has the form of a difference equation (lattice equation). \( n \) corresponds to time and \( m \) corresponds to position. We know the Euler approximations of the first and second derivatives</p><p><span>\[\pdv{f}{t} \approx \frac{f_{n+1} - f_n}{\tau} \qquad \tau \rightarrow 0\]
</span><span>\[\pdv{^2 f}{x^2} \approx \frac{f_{m+1} - 2 f_m + f_{m-1}}{h^2} \quad h \rightarrow 0\]</span></p><p>Writing the difference equation in the same kind of form:</p><span>\[\frac{f_{n+1} (m) - f_n (m)}{\tau} = \frac{- h^2}{2 \tau} \left( \frac{f_n(m+1) - 2f_n (m) + f_n (m-1)}{h^2} \right)\]</span><p>We have something that really looks like the diffusion equation. But, we need to be careful when we take the limit \( \tau \rightarrow 0, h \rightarrow 0 \). In particular, we need to take the limits such that \( D \equiv \frac{h^2}{2 \tau} \) is constant. If we do that as we take the limit, we arrive at the partial differential equation
<span>\[\pdv{f}{t} = D \pdv{^2 f}{x^2}\]
</span><span>\[D = \frac{(\Delta x)^2}{2 \Delta t}\]</span></p><p>Random motion produces diffusion!</p><ul><li>If we were to include a non-symmetric term, and say that the random walker has a tendency to move in one direction so that \( p \neq 1/2 \), then we would find a drift motion. The resulting system is the Fokker-Planck equation.</li><li>The Heat equation
<span>\[\partial _t u = D \partial_{xx} u\]
</span>has a fundamental solution
<span>\[u(x, t = 0) = \delta (x)\]
</span><span>\[\rightarrow u(x, t) = \frac{1}{\sqrt{2 \pi} \sqrt{2 D t}} e^{- \frac{2^2}{2 (2Dt)}}\]
</span>The fundamental behavior of the heat equation is that structures spread out as
<span>\[u \sim \frac{1}{\sqrt{t}}\]
</span>and do so at a rate \( D \).</li></ul><h2 id=kinetic-theory>Kinetic Theory
<a class=anchor href=#kinetic-theory>#</a></h2><p><strong>Introduction to phase space mechanics</strong></p><p>Consider 1-dimensional particle motion with position \( x \) and velocity \( v \)</p><p><span>\[\dot x = v\]
</span><span>\[\dot v = F(x) / m\]</span></p><p>If we let the mechanical state of the particle be \( (x, v) \), the state can be represented graphically by a point in the \( x \)-\( v \) plane which we call phase space. Looking at the motion in phase space can make it a lot easier to view the phase of motion.</p><p>We can define the flux vector for the motion as
<span>\[\vec r \equiv (\vec x, \vec v)\]
</span><span>\[\dot \vec r = \vec F (\vec r)\]
</span>analogous to the velocity field in a fluid. The fluid analogy leads tot he concept of phase flow on the streamlines of \( \vec F(\vec r) \) in the phase space.</p><p>As an example, consider the normalized pendulum</p><p><span>\[\dot x = v\]
</span><span>\[\dot v = \sin x\]</span></p><p>We can deduce streamlines by looking at constants of motion
<span>\[\dv{C}{t} = 0\]
</span><span>\[\dv{}{t} C(x, v) = \pdv{C}{x}\dot x + \pdv{C}{v} \dot v = 0\]
</span>One way to solve this is to pick
<span>\[\pdv{C}{v} = \dot x\]
</span>and
<span>\[\pdv{C}{x} = - \dot v\]</span></p><p>We can solve these independently
<span>\[\pdv{C}{v} = v \rightarrow C(x, v) = \frac{1}{2} v^2 + f(x)\]
</span><span>\[\pdv{C}{x} = - \dot v\]
</span>When we have a spatially-dependent quantity of this form (force divided by mass), we can identify \( C \) as a potential \( \Phi(x) \).
<span>\[C(x, v) = \frac{1}{2} v^2 + \Phi (x) / m + C_0\]
</span>and write out a Hamiltonian
<span>\[H = \frac{1}{2} m v^2 + \Phi (x) + H_0\]
</span>with Hamilton&rsquo;s equations
<span>\[m \dot x = \pdv{H}{v}\]
</span><span>\[\dot v = - \pdv{H}{x} \frac{1}{m}\]</span></p><p>By picking a potential, we can visualize at the phase portrait (streamlines of the phase flux) by looking at surfaces of constant \( H \), which is conserved on trajectories. For the pendulum problem
<span>\[H = \frac{1}{2} \dot \theta ^2 - \frac{g}{l} \cos \theta\]</span></p><p>If we plot these contours, we&rsquo;ll get elliptical sorts of shapes out to a point, then free contours that do not close on themselves. The trapped contours are motions of the pendulum that swing back and forth, while free contours correspond to the pendulum swinging all the way around. The contour that separates free from trapped contours is called the separatrix.</p><p><span>\[H &lt; 0 \rightarrow \text{trapped motion}\]
</span><span>\[H = 0 \rightarrow \text{separatrix}\]
</span><span>\[H > 0 \rightarrow \text{free motion}\]</span></p><p>Consider an electron in a plasma wave of field
<span>\[E(x) = A \sin (kx - \omega t)\]
</span><span>\[\dot x = v\]
</span><span>\[\dot v = - \frac{e}{m} A \sin (kx - \omega t)\]</span></p><p>Looks familiar! We&rsquo;ll see the same pendulum class phase portrait for particles in the simplest kind of plasma wave. The pendulum phase portrait is critical to the idea of wave-particle interaction.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/Peppyhare/r/commit/d9d2e6346430fb02696144122a65f59fdbbb22e6 title='Last modified by Evan Bluhm | February 25, 2023' target=_blank rel=noopener><img src=/r/svg/calendar.svg class=book-icon alt>
<span>February 25, 2023</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#mathematical-review>Mathematical review</a><ul><li><a href=#fourier-series--spectral-analysis>Fourier Series / Spectral Analysis</a><ul><li><a href=#sturm-liouville-theory>Sturm-Liouville Theory</a></li></ul></li><li><a href=#series-with-finite-spectra>Series with finite spectra</a><ul><li><a href=#fourier-series-with-infinite-spectra>Fourier series with infinite spectra</a></li></ul></li><li><a href=#the-fourier-transform>The Fourier Transform</a></li><li><a href=#laplace-transform>Laplace Transform</a></li><li><a href=#important-fourier-transforms>Important Fourier Transforms</a><ul><li><a href=#unitary-fourier-transform>Unitary Fourier Transform</a></li><li><a href=#multi-dimensional-fourier-transforms>Multi-dimensional Fourier Transforms</a></li><li><a href=#space-time-fourier-transform>Space-time Fourier Transform</a></li></ul></li><li><a href=#putting-it-all-together>Putting it all together</a></li><li><a href=#dispersion-relation>Dispersion Relation</a><ul><li><a href=#phase-velocity>Phase velocity</a></li><li><a href=#group-velocity>Group velocity</a></li><li><a href=#growthdecay-of-modes-and-energy-as-a-complex-time-frequency>Growth/decay of modes and energy as a complex time frequency</a></li></ul></li><li><a href=#diffusion>Diffusion</a><ul><li><a href=#probability-distributions>Probability Distributions</a></li><li><a href=#statistical-moments>Statistical Moments</a></li><li><a href=#law-of-large-numbers>Law of Large Numbers</a></li><li><a href=#central--limit-theorem>Central Limit Theorem</a></li><li><a href=#random-walks-and-diffusion>Random Walks and Diffusion</a></li></ul></li><li><a href=#kinetic-theory>Kinetic Theory</a></li></ul></li></ul></nav></div></aside></main></body></html>